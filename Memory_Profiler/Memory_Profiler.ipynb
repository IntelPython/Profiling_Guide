{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b705c253-6485-46ff-b071-6bd1347916bf",
   "metadata": {},
   "source": [
    "# Memory Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d0713-cff0-4224-87da-fc43d1304a44",
   "metadata": {},
   "source": [
    "This is a python module for monitoring memory consumption of a process as well as line-by-line analysis of memory consumption for python programs. It is a pure python module which depends on the **[psutil](http://pypi.python.org/pypi/psutil)** module. It is one kind of profiling where we measure space complexity (memory consumption) of a program/process. <br>\n",
    "\n",
    "An important thing to remember is that memory-profiler itself consumes a **significant amount of memory**. Use this only in development but avoid it in production. <br>\n",
    "**Ways to Profile Memory Usage Of Python Code using \"memory_profiler\"** <br>\n",
    "- **@profile Decorator** - Used to profile memory usage of individual Python functions. Provide statistics showing memory usage by an individual line of python code.\n",
    "- **mprof Shell/Command Line Command** - Used to profile memory usage of whole Python script (\".py\" file) as a function of time. It'll let us analyze memory usage during code run time rather than by individual line of code.\n",
    "- **memory_usage() function** - Used to profile memory usage of process, python statements, and Python functions for a specified time interval.\n",
    "- **mprun & memit cell/line Magic commands of Jupyter notebook** - Used to profile memory usage of individual python statement or code of whole cell in Jupyter Notebook.\n",
    "\n",
    "**To Know more about memory_profiler visit the [github_repo](https://github.com/pythonprofilers/memory_profiler)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6cd67-7952-44af-b356-3298f4d9255d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60d15db-00ae-4be3-ac12-d8d4c7130286",
   "metadata": {},
   "source": [
    "Install via pip::\n",
    "\n",
    "    $ pip install -U memory_profiler\n",
    "\n",
    "The package is also available on `conda-forge\n",
    "<https://github.com/conda-forge/memory_profiler-feedstock>`\n",
    "\n",
    "To install from source, download the package, extract and type:\n",
    "\n",
    "    $ pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468a73d-1bcf-4e94-8e7e-5d8c27572367",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Example to use @profile Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565ce3c-e5ad-4ab2-bb4e-9bfc2531a46d",
   "metadata": {},
   "source": [
    "Use @profile decorator above the function you want to profile. <br> \n",
    "Create a file **example1.py** with below code and **uncomment** the code<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "972a4b1b-0655-4aa8-a8b0-c9aba198907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from memory_profiler import profile\n",
    "# import random\n",
    "\n",
    "# @profile\n",
    "# def random_number_generator():\n",
    "#     arr1 = [random.randint(1,10) for i in range(100000)]\n",
    "#     arr2 = [random.randint(1,10) for i in range(100000)]\n",
    "#     arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
    "#     del arr1\n",
    "#     del arr2\n",
    "#     tot = sum(arr3)\n",
    "#     del arr3\n",
    "#     print(tot)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     random_number_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b811006-e4f4-41c2-84e5-b39fbf7c1ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101973\n",
      "Filename: example1.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     4     41.2 MiB     41.2 MiB           1   @profile\n",
      "     5                                         def random_number_generator():\n",
      "     6     42.5 MiB      1.3 MiB      100003       arr1 = [random.randint(1,10) for i in range(100000)]\n",
      "     7     43.4 MiB      0.9 MiB      100003       arr2 = [random.randint(1,10) for i in range(100000)]\n",
      "     8     44.2 MiB      0.9 MiB      100003       arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
      "     9     43.5 MiB     -0.8 MiB           1       del arr1\n",
      "    10     42.7 MiB     -0.8 MiB           1       del arr2\n",
      "    11     42.7 MiB      0.0 MiB           1       tot = sum(arr3)\n",
      "    12     42.0 MiB     -0.8 MiB           1       del arr3\n",
      "    13     42.0 MiB      0.0 MiB           1       print(tot)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m memory_profiler example1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d782de-bdfa-47a5-bed9-a691729f97c7",
   "metadata": {},
   "source": [
    "The output has 5 columns:\n",
    "\n",
    "- **Line #**: Line Number\n",
    "- **Line Contents**: Python code at each line number\n",
    "- **Mem usage**: Memory usage by the Python interpreter after every execution of the line.\n",
    "- **Increment**: Difference in memory consumption from the current line to the last line. It basically denotes the memory consumed by a particular line of Python code.\n",
    "- **Occurrences**: Number of times a particular line of code is executed.\n",
    "\n",
    "Mem Usage can be tracked to observe the total memory occupancy by the Python interpreter, whereas the Increment column can be observed to see the memory consumption for a particular line of code. By observing the memory usage one can optimize the memory consumption to develop a production-ready code. This gives us the best idea of how much memory in total is getting used and how much a particular variable is using for better decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1ccd4-db18-4170-be03-f536b08b7122",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example to use high precision and save results to log file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946418c-269d-4b82-af9e-c0907e155382",
   "metadata": {},
   "source": [
    "Create a file **example2.py** with below code and **uncomment** the code<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbc65a8-4f71-4cac-83f3-f3cca2e2e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from memory_profiler import profile\n",
    "# import random\n",
    "# fp = open(\"./Memory_Profiler/example_report.log\", \"w+\")\n",
    "# @profile(precision=4,stream=fp)\n",
    "# def random_number_generator():\n",
    "#     arr1 = [random.randint(1,10) for i in range(100000)]\n",
    "#     arr2 = [random.randint(1,10) for i in range(100000)]\n",
    "#     arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
    "#     del arr1\n",
    "#     del arr2\n",
    "#     tot = sum(arr3)\n",
    "#     del arr3\n",
    "#     print(tot)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     random_number_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7dfd258-51db-4316-a720-7507ec36e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101948\n"
     ]
    }
   ],
   "source": [
    "!python -m memory_profiler example2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469bada-6e2d-41fa-9c20-e97f9a4be15f",
   "metadata": {},
   "source": [
    "To view results, use **cat** command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c7381e-d851-4653-831f-b4d3f5376b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: example2.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     4  41.2031 MiB  41.2031 MiB           1   @profile(precision=4,stream=fp)\n",
      "     5                                         def random_number_generator():\n",
      "     6  42.7539 MiB   1.5508 MiB      100003       arr1 = [random.randint(1,10) for i in range(100000)]\n",
      "     7  43.4219 MiB   0.6680 MiB      100003       arr2 = [random.randint(1,10) for i in range(100000)]\n",
      "     8  44.2266 MiB   0.8047 MiB      100003       arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
      "     9  43.5273 MiB  -0.6992 MiB           1       del arr1\n",
      "    10  42.7617 MiB  -0.7656 MiB           1       del arr2\n",
      "    11  42.7617 MiB   0.0000 MiB           1       tot = sum(arr3)\n",
      "    12  41.9961 MiB  -0.7656 MiB           1       del arr3\n",
      "    13  41.9961 MiB   0.0000 MiB           1       print(tot)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat \"example_report.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c79b1-43d1-495a-8def-bc9e3a256e75",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example to use **memory_profiler** for **intelligent_indexing** ref kit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bdb5a-c01f-4a60-bad0-3c1b84ef67da",
   "metadata": {},
   "source": [
    "The **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** ref kit demonstrates one way of building an NLP pipeline for classifying documents to their respective topics and describe how we can leverage the **Intel® AI Analytics Toolkit (AI Kit)** to accelerate the pipeline.\n",
    "\n",
    "**Intel® AI Analytics Toolkit (AI Kit)** is used to achieve quick results even when the data for a model are huge. It provides the capability to reuse the code present in different languages so that the hardware utilization is optimized to provide these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e80bfd-41fd-4078-99f7-e8e636616b8f",
   "metadata": {},
   "source": [
    "The **Intelligent Indexing** ref kit has different Intel® oneAPI optimizations enabled like:\n",
    "- **[Intel® Distribution of Modin*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-of-modin.html#gs.v03x2l)**\n",
    "The Intel® Distribution of Modin* is a performant, parallel, and distributed dataframe system that is designed around enabling data scientists to be more productive. It provides drop-in acceleration to your existing **pandas** workflows. No upfront cost to learning a new API. Integrates with the Python* ecosystem. Seamlessly scales across multicores with Ray* and Dask* clusters (run on and with what you have)\n",
    "- **[Intel® Extension for Scikit-learn*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/scikit-learn.html)**\n",
    "Designed for data scientists, Intel® Extension for Scikit-Learn* is a seamless way to speed up your Scikit-learn applications for machine learning to solve real-world problems. This extension package dynamically patches scikit-learn estimators to use Intel® oneAPI Data Analytics Library (oneDAL) as the underlying solver, while achieving the speed up for your machine learning algorithms out-of-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dade819-de35-4b02-b485-8c21f62ee385",
   "metadata": {},
   "source": [
    "**NOTE** Please visit the **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** Ref kit page to know more about the kit.\n",
    "- Please follow the steps in github repo to clone and create the environment.\n",
    "- After creating environment install **memory_profiler** in both the environments **doc_class_stock** and **doc_class_intel** using\n",
    "```\n",
    "pip install -U memory_profiler\n",
    "```\n",
    "We will be using **memory_profiler** to profile this workload below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c6e4f-66ed-4b1a-b87d-6d780c49d020",
   "metadata": {},
   "source": [
    "Just add the **@profile** decorator at the top of functions you want to profile. <br>\n",
    "Modify the **run_benchmarks.py (Location '../intelligent-indexing/src/run_benchmarks.py')** file to add **@profile** decorators as shown below <br>\n",
    "\n",
    "**get_data() function**\n",
    "```\n",
    "from memory_profiler import profile\n",
    "@profile(precision=4,stream = fp)\n",
    "def get_data(path_to_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"Read in and clean data\n",
    "    Args:\n",
    "        path_to_csv (str): processed data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path_to_csv)[\n",
    "        ['category', 'headline', 'short_description', 'link']\n",
    "    ]\n",
    "    data = data.dropna(subset=['headline', 'short_description', 'link'])\n",
    "\n",
    "    data.link = data.link.apply(clean_link)\n",
    "    data.short_description = data.short_description \\\n",
    "        .apply(clean_short_description)\n",
    "    data.headline = data.headline.apply(clean_headline)\n",
    "\n",
    "    data['text'] = data.link + \" \" + data.short_description \\\n",
    "        + \" \" + data.headline\n",
    "    data['tokens'] = data.text.apply(tokenize)\n",
    "    return data\n",
    "```\n",
    "<br>\n",
    "\n",
    "**Create a function train_data()**\n",
    "```\n",
    "@profile(precision=4,stream = fp)\n",
    "def train_data(train,test):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "    min_df=50,\n",
    "    lowercase=False,\n",
    "    tokenizer=lambda x: x)\n",
    "                                    \n",
    "    svc = SVC()\n",
    "    svc.fit(vectorizer.fit_transform(train.tokens), train.category)\n",
    "    training_time = time.time()\n",
    "    y_pred = svc.predict(vectorizer.transform(test.tokens))\n",
    "    return svc, training_time, y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc0092-87ea-44d7-b3e3-df5a177831d5",
   "metadata": {},
   "source": [
    "**NOTE** : To save log files at appropriate locations. Add  <br>\n",
    "**While profiling stock**\n",
    "```\n",
    "fp = open(\"../../Profiling_Guide/Memory_Profiler/Memory_Profiler_Results/stock_results/stock_report.log\", \"w+\") ## For stock results\n",
    "```\n",
    "**While profiling intel extension**\n",
    "```\n",
    "fp = open(\"../../Profiling_Guide/Memory_Profiler/Memory_Profiler_Results/oneapi_optimized_results/intel_report.log\", \"w+\") ## For oneapi_optimized_results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74524a72-b241-42a7-ae6a-b1e46fea3293",
   "metadata": {},
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4611f0-18d2-4395-87ce-d9c96e36e490",
   "metadata": {},
   "source": [
    "To run the profiler on the intelligent indexing ref kit <br>\n",
    "- Navigate to directory **intelligent-indexing/src/** in terminal\n",
    "- ```conda activate doc_class_stock```\n",
    "- execute the below commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8cfff6-87ce-4c49-9d45-0affffdeed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m memory_profiler run_benchmarks.py -l \"../logs/stock_stock.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc62c41-c381-4dcc-ad7f-fae3055d82fd",
   "metadata": {},
   "source": [
    "To visualize the results execute the below command from the **intelligent-indexing/src/** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350fee6-2f30-4d25-bfd7-8c189228af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat \"../../Profiling_Guide/Memory_Profiler/Memory_Profiler_Results/stock_results/stock_report.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c461fd-0e04-42c2-bbce-c6c7824956fc",
   "metadata": {},
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Intel oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4a5f0-2323-45ff-ade8-7ad72de991ba",
   "metadata": {},
   "source": [
    "To run the profiler on the intelligent indexing ref kit <br>\n",
    "- Navigate to directory **intelligent-indexing/src/** in terminal\n",
    "- ```conda activate doc_class_intel```\n",
    "- execute the below commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba9188-e462-4d31-b7fa-389d0142d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m memory_profiler run_benchmarks.py -i -l \"../logs/intel_intel.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71814a6-3493-4d90-951e-866b79b9c81f",
   "metadata": {},
   "source": [
    "To visualize the results execute the below command from the **intelligent-indexing/src/** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf76053-2077-4ffd-8151-9182b8a6d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat \"../../Profiling_Guide/Memory_Profiler/Memory_Profiler_Results/oneapi_optimized_results/intel_report.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891727cc-58d1-4523-a2e0-46491353c7c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Example to use **mprof** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eeb23a-c283-40e8-9d07-6dc492a3db24",
   "metadata": {},
   "source": [
    "Use @profile decorator above the function you want to profile. <br> \n",
    "Create a file **example1.py** with below code and **uncomment** the code<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7e2ab49-8b67-4a1c-ab2d-411fea34dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from memory_profiler import profile\n",
    "# import random\n",
    "\n",
    "# @profile\n",
    "# def random_number_generator():\n",
    "#     arr1 = [random.randint(1,10) for i in range(100000)]\n",
    "#     arr2 = [random.randint(1,10) for i in range(100000)]\n",
    "#     arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
    "#     del arr1\n",
    "#     del arr2\n",
    "#     tot = sum(arr3)\n",
    "#     del arr3\n",
    "#     print(tot)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     random_number_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012d2c18-c003-4844-8534-80201a6c45c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n",
      "1098869\n",
      "Filename: example1.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     4     41.1 MiB     41.1 MiB           1   @profile\n",
      "     5                                         def random_number_generator():\n",
      "     6     42.5 MiB      1.4 MiB      100003       arr1 = [random.randint(1,10) for i in range(100000)]\n",
      "     7     43.4 MiB      0.9 MiB      100003       arr2 = [random.randint(1,10) for i in range(100000)]\n",
      "     8     44.1 MiB      0.7 MiB      100003       arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
      "     9     43.4 MiB     -0.7 MiB           1       del arr1\n",
      "    10     42.6 MiB     -0.8 MiB           1       del arr2\n",
      "    11     42.6 MiB      0.0 MiB           1       tot = sum(arr3)\n",
      "    12     41.9 MiB     -0.8 MiB           1       del arr3\n",
      "    13     41.9 MiB      0.0 MiB           1       print(tot)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mprof run example1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e269f6f-7de4-444d-82c3-74cb7c90e313",
   "metadata": {},
   "source": [
    "The above command will execute the script and generate the new file by name **mprofile_[current_datetime].dat**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84376b61-b786-492c-ac9f-c670103652a6",
   "metadata": {},
   "source": [
    "mprof command has different parameters\n",
    "- **--interval INTERVAL or -T INTERVAL** - As we had mentioned earlier, \"mprof\" records memory usage every \"0.1\" second by default. We can override this setting using this parameter. We can give time interval in seconds here.\n",
    "- **--timeout TIMEOUT or -t TIMEOUT** - By default, \"mprof\" monitors total execution of program/process. We can instruct it to stop monitoring after a specified amount of time using this parameter. It let us specify a time in seconds.\n",
    "- **--output FILENAME or -o FILENAME** - We can direct the result of profiling to an output file using this command. By default, \"mprof\" creates a file named \"mprofile_datetime.dat\". We can override that using this argument.\n",
    "- **--backend BACKEND** - This command let us specify backend for profiling. The default is \"psutil\" as we had mentioned a few times earlier. We would recommend users to stick to default as other backends do not seem reliable yet.\n",
    "- **--include-children** - It monitors memory usage across all children of process and shows their usage as one line chart.\n",
    "- **--multiprocess** - It generates a sample line chart for each sub-process and their memory usage per time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8e95a0-b14b-4d42-908b-d519514d360c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using last profile data.\n"
     ]
    }
   ],
   "source": [
    "!mprof plot -o mprof_example1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afdee9-d16d-4c3b-9e99-4a7a5de74e2a",
   "metadata": {},
   "source": [
    "mprof plot has different parameters like\n",
    "- **-o** :  To save plot to output file\n",
    "- **-t** : To give title to plot <br>\n",
    "It automatically takes the latest .dat file created by mprof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17d3db-47f3-4a62-bead-89995fc0c28c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example to use **mprof** for **intelligent_indexing** ref kit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3248e-d309-4272-babf-1738293e06da",
   "metadata": {},
   "source": [
    "Just add the **@profile** decorator at the top of functions you want to profile. <br>\n",
    "Modify the run_benchmarks.py file to add **@profile** decorators as shown in above example for **intelligent-indexing**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1ad7e-e057-4fe1-b241-ebd8a15c0def",
   "metadata": {},
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d58eb-d454-42d6-9c6e-fb026738c1ff",
   "metadata": {},
   "source": [
    "To run the profiler on the intelligent indexing ref kit <br>\n",
    "- Navigate to directory **intelligent-indexing/src/** in terminal\n",
    "- ```conda activate doc_class_stock```\n",
    "- execute the below commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7611291-cc29-40af-b933-f375b330d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mprof run --output '../../Profiling_Guide/Memory_Profiler/Memory_Profiler_Results/stock_results/stock_output.dat' --python python run_benchmarks.py -l \"../logs/stock_stock.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b290ad-1577-4109-b67a-241081d1e0e6",
   "metadata": {},
   "source": [
    "To visualize the results execute the below command from the **Memory_Profiler/Memory_Profiler_Results/stock_results/** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf61740-e05b-4fc8-9539-ab06397c2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mprof plot -o stock_output.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e3599-ba33-4da0-bb44-f1a9f542f2ec",
   "metadata": {},
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Intel oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51408ce7-da26-4b9a-a5c3-6362775f0467",
   "metadata": {},
   "source": [
    "To run the profiler on the intelligent indexing ref kit <br>\n",
    "- Navigate to directory **intelligent-indexing/src/** in terminal\n",
    "- ```conda activate doc_class_intel```\n",
    "- execute the below commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53085275-4f08-47ca-82f4-f1769413be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mprof run --output '../../Profiling_Guide/Memory_Profiler/Memory_Profiler_Results/oneapi_optimized_results/intel_output.dat' --python python run_benchmarks.py -i -l \"../logs/intel_intel.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ada9b-2f76-4ee7-9f65-0d7f6e82b356",
   "metadata": {},
   "source": [
    "To visualize the results execute the below command from the **Memory_Profiler/Memory_Profiler_Results/oneapi_optimized_results/** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b7275-50d0-4e44-99cc-a8130f5d26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mprof plot -o intel_output.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683483ae-0d00-4185-bc06-dfce14c69451",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Example to use **memory_usage()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaddb0d-efb4-4712-8ecd-cdd248a9dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def random_generator(sz=1000):\n",
    "    time.sleep(5)\n",
    "    arr1 = np.random.randint(1,100, size=(sz, sz))\n",
    "    avg = arr1.mean()\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e9c7d83-663b-419a-8c7a-ed322741ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65.984375, 1682322349.1823976),\n",
       " (66.21875, 1682322349.2092044),\n",
       " (66.21875, 1682322349.3104758),\n",
       " (66.21875, 1682322349.4110591),\n",
       " (66.21875, 1682322349.511631),\n",
       " (66.21875, 1682322349.612216),\n",
       " (66.21875, 1682322349.7127843),\n",
       " (66.21875, 1682322349.8133283),\n",
       " (66.21875, 1682322349.9138525),\n",
       " (66.21875, 1682322350.0143762),\n",
       " (66.21875, 1682322350.1149023),\n",
       " (66.21875, 1682322350.2154295),\n",
       " (66.21875, 1682322350.3159516),\n",
       " (66.21875, 1682322350.416493),\n",
       " (66.21875, 1682322350.517037),\n",
       " (66.21875, 1682322350.6175709),\n",
       " (66.21875, 1682322350.718097),\n",
       " (66.21875, 1682322350.8186202),\n",
       " (66.21875, 1682322350.9191444),\n",
       " (66.21875, 1682322351.019676),\n",
       " (66.21875, 1682322351.120203),\n",
       " (66.21875, 1682322351.220736),\n",
       " (66.21875, 1682322351.32128),\n",
       " (66.21875, 1682322351.4218082),\n",
       " (66.21875, 1682322351.5223436),\n",
       " (66.21875, 1682322351.6228833),\n",
       " (66.21875, 1682322351.7234464),\n",
       " (66.21875, 1682322351.824025),\n",
       " (66.21875, 1682322351.9245908),\n",
       " (66.21875, 1682322352.0251849),\n",
       " (66.21875, 1682322352.1257675),\n",
       " (66.21875, 1682322352.2263374),\n",
       " (66.21875, 1682322352.3269064),\n",
       " (66.21875, 1682322352.4274778),\n",
       " (66.21875, 1682322352.5280466),\n",
       " (66.21875, 1682322352.6286156),\n",
       " (66.21875, 1682322352.7291849),\n",
       " (66.21875, 1682322352.8297668),\n",
       " (66.21875, 1682322352.9303324),\n",
       " (66.21875, 1682322353.0308995),\n",
       " (66.21875, 1682322353.1314662),\n",
       " (66.21875, 1682322353.2320323),\n",
       " (66.21875, 1682322353.332599),\n",
       " (66.21875, 1682322353.4331656),\n",
       " (66.21875, 1682322353.5336905),\n",
       " (66.21875, 1682322353.6342165),\n",
       " (66.21875, 1682322353.7347465),\n",
       " (66.21875, 1682322353.8352773),\n",
       " (66.21875, 1682322353.9358187),\n",
       " (66.21875, 1682322354.0363505),\n",
       " (66.21875, 1682322354.136883),\n",
       " (69.92578125, 1682322354.237432),\n",
       " (66.94140625, 1682322354.2643769)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_usage = memory_usage((random_generator, (1000,), ), timestamps=True, interval=0.1)\n",
    "mem_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd843c-b78b-40c2-b1cf-e9ad246e6d78",
   "metadata": {},
   "source": [
    "To Profile using **memory_usage**. We need one of the following\n",
    "- **Process**: We need to provide process id as an integer or string.\n",
    "- **Python Function**: The function followed by its arguments needs to be provided as a tuple. <br>\n",
    "\n",
    "In the above example we use\n",
    "- **Python function**: random_generator\n",
    "- **interval**: 0.1 seconds\n",
    "- **timestamps**: True, will return the timestamps at which memory_usage was recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b4ae6-013d-43d0-abac-218823dddf85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. Example to use **mprun** and **memit** magic line commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20fa882-7377-4d7e-8822-656d1f53e236",
   "metadata": {},
   "source": [
    "The memory_profiler provides 2 line magic commands and 2 cell magic commands to be used in jupyter notebooks.\n",
    "\n",
    "- **Line Magic Commands**: %mprun & %memit\n",
    "- **Cell Magic Commands**: %%mprun & %%memit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764e110-2f37-4bde-b921-5c927f53136e",
   "metadata": {},
   "source": [
    "To **enable memory_profiler** in jupyter notebook, load the extension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1af09ea3-ea67-4611-8a94-1a2a08715b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a05581-4299-4517-8cdf-f66da83447d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create an example3.py with following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94028fae-02ba-480f-8b79-e3564bb83554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# @profile\n",
    "# def very_slow_random_generator():\n",
    "#     time.sleep(5)\n",
    "#     arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "#     avg = arr1.mean()\n",
    "#     return avg\n",
    "\n",
    "# @profile\n",
    "# def slow_random_generator():\n",
    "#     time.sleep(2)\n",
    "#     arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "#     avg = arr1.mean()\n",
    "#     return avg\n",
    "\n",
    "# @profile\n",
    "# def main_func():\n",
    "#     avg1 = slow_random_generator()\n",
    "#     avg2 = very_slow_random_generator()\n",
    "\n",
    "#     print(\"Averages: {:.3f}, {:.3f}\".format(avg1,avg2))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af88c77-2d8f-4e9d-84b3-35bb88772f13",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **%mprun** magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee26bb5-3bfd-4987-9406-6eeefbcb55c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages: 50.001, 49.966\n",
      "\n",
      "\n",
      "*** Profile printout saved to text file slow_profile_dump.log. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /ws2/yfulwani/Profiling_Guide/Memory_Profiler/example3.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "     4     75.8 MiB     75.8 MiB           1   def very_slow_random_generator():\n",
       "     5     75.8 MiB      0.0 MiB           1       time.sleep(5)\n",
       "     6     75.8 MiB      0.0 MiB           1       arr1 = np.random.randint(1,100, size=(1000,1000))\n",
       "     7     75.8 MiB      0.0 MiB           1       avg = arr1.mean()\n",
       "     8     75.8 MiB      0.0 MiB           1       return avg\n",
       "\n",
       "\n",
       "Filename: /ws2/yfulwani/Profiling_Guide/Memory_Profiler/example3.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "    11     68.2 MiB     68.2 MiB           1   def slow_random_generator():\n",
       "    12     68.2 MiB      0.0 MiB           1       time.sleep(2)\n",
       "    13     75.8 MiB      7.5 MiB           1       arr1 = np.random.randint(1,100, size=(1000,1000))\n",
       "    14     75.8 MiB      0.0 MiB           1       avg = arr1.mean()\n",
       "    15     75.8 MiB      0.0 MiB           1       return avg\n",
       "\n",
       "\n",
       "Filename: /ws2/yfulwani/Profiling_Guide/Memory_Profiler/example3.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "    17     68.2 MiB     68.2 MiB           1   def main_func():\n",
       "    18     75.8 MiB     75.8 MiB           1       avg1 = slow_random_generator()\n",
       "    19     75.8 MiB     75.8 MiB           1       avg2 = very_slow_random_generator()\n",
       "    20                                         \n",
       "    21     75.8 MiB      0.0 MiB           1       print(\"Averages: {:.3f}, {:.3f}\".format(avg1,avg2))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from example3 import very_slow_random_generator,\\\n",
    "                                    slow_random_generator,\\\n",
    "                                    main_func\n",
    "\n",
    "%mprun -f very_slow_random_generator -T slow_profile_dump.log -f slow_random_generator -f main_func main_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d5232-e72a-43d3-8231-c32b0dd5f7dd",
   "metadata": {},
   "source": [
    "**mprun** has following parameters\n",
    "- **-f**: To specify what functions to profile\n",
    "- **-T**: Specify after function to save results for that function at a particular path <br>\n",
    "\n",
    "\n",
    "In above example the **very_slow_random_generator**, **slow_random_generator**, **main_function** are profiled and results of **very_slow_random_generator** are saved to **slow_profile_dump.log**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc5f98-591e-4857-b038-d5d887366aa4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **%memit** Line Magic Command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426af4f-e862-4beb-8033-7800dbd3114f",
   "metadata": {},
   "source": [
    "The **%memit** cell command works for whole cell and reports **peak memory usage** of the whole cell. We run it for the random_generator function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc2c5d6f-2683-467d-b858-854b1dcd7cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 94.23 MiB, increment: 0.01 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit random_generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
