{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b705c253-6485-46ff-b071-6bd1347916bf",
   "metadata": {},
   "source": [
    "# Memory Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d0713-cff0-4224-87da-fc43d1304a44",
   "metadata": {},
   "source": [
    "**Ways to Profile Memory Usage Of Python Code using \"memory_profiler\"** <br>\n",
    "- **@profile Decorator** - Used to profile memory usage of individual Python functions. Provide statistics showing memory usage by an individual line of python code.\n",
    "- **mprof Shell/Command Line Command** - Used to profile memory usage of whole Python script (\".py\" file) as a function of time. It'll let us analyze memory usage during code run time rather than by individual line of code.\n",
    "- **memory_usage() function** - Used to profile memory usage of process, python statements, and Python functions for a specified time interval.\n",
    "- **mprun & memit cell/line Magic commands of Jupyter notebook** - Used to profile memory usage of individual python statement or code of whole cell in Jupyter Notebook.\n",
    "\n",
    "**To Know more about memory_profiler visit the [github_repo](https://github.com/pythonprofilers/memory_profiler)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6cd67-7952-44af-b356-3298f4d9255d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60d15db-00ae-4be3-ac12-d8d4c7130286",
   "metadata": {},
   "source": [
    "Install via pip::\n",
    "\n",
    "    $ pip install -U memory_profiler\n",
    "\n",
    "The package is also available on `conda-forge\n",
    "<https://github.com/conda-forge/memory_profiler-feedstock>`_.\n",
    "\n",
    "To install from source, download the package, extract and type::\n",
    "\n",
    "    $ pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468a73d-1bcf-4e94-8e7e-5d8c27572367",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Example to use @profile Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565ce3c-e5ad-4ab2-bb4e-9bfc2531a46d",
   "metadata": {},
   "source": [
    "Use @profile decorator above the function you want to profile. <br> \n",
    "Here is a file **example1.py** with below code <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a4b1b-0655-4aa8-a8b0-c9aba198907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "import random\n",
    "\n",
    "@profile\n",
    "def random_number_generator():\n",
    "    arr1 = [random.randint(1,10) for i in range(100000)]\n",
    "    arr2 = [random.randint(1,10) for i in range(100000)]\n",
    "    arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
    "    del arr1\n",
    "    del arr2\n",
    "    tot = sum(arr3)\n",
    "    del arr3\n",
    "    print(tot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random_number_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b811006-e4f4-41c2-84e5-b39fbf7c1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m memory_profiler example1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d782de-bdfa-47a5-bed9-a691729f97c7",
   "metadata": {},
   "source": [
    "The output has 5 columns:\n",
    "\n",
    "- **Line #**: Line Number\n",
    "- **Line Contents**: Python code at each line number\n",
    "- **Mem usage**: Memory usage by the Python interpreter after every execution of the line.\n",
    "- **Increment**: Difference in memory consumption from the current line to the last line. It basically denotes the memory consumed by a particular line of Python code.\n",
    "- **Occurrences**: Number of times a particular line of code is executed.\n",
    "\n",
    "Mem Usage can be tracked to observe the total memory occupancy by the Python interpreter, whereas the Increment column can be observed to see the memory consumption for a particular line of code. By observing the memory usage one can optimize the memory consumption to develop a production-ready code. This gives us the best idea of how much memory in total is getting used and how much a particular variable is using for better decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1ccd4-db18-4170-be03-f536b08b7122",
   "metadata": {},
   "source": [
    "### Example to use high precision and save results to log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc65a8-4f71-4cac-83f3-f3cca2e2e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "import random\n",
    "fp = open(\"./Memory_Profiler/example_report.log\", \"w+\")\n",
    "@profile(precision=4,stream=fp)\n",
    "def random_number_generator():\n",
    "    arr1 = [random.randint(1,10) for i in range(100000)]\n",
    "    arr2 = [random.randint(1,10) for i in range(100000)]\n",
    "    arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
    "    del arr1\n",
    "    del arr2\n",
    "    tot = sum(arr3)\n",
    "    del arr3\n",
    "    print(tot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random_number_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfd258-51db-4316-a720-7507ec36e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m memory_profiler example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469bada-6e2d-41fa-9c20-e97f9a4be15f",
   "metadata": {},
   "source": [
    "To view results, use **cat** command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7381e-d851-4653-831f-b4d3f5376b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"./Memory_Profiler/example_report.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c79b1-43d1-495a-8def-bc9e3a256e75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Example to use **memory_profiler** for **intelligent_indexing** ref kit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c6e4f-66ed-4b1a-b87d-6d780c49d020",
   "metadata": {},
   "source": [
    "Just add the **@profile** decorator at the top of functions you want to profile. <br>\n",
    "Modify the run_benchmarks.py file to add **@profile** decorators as shown below <br>\n",
    "\n",
    "**get_data() function**\n",
    "```\n",
    "@profile(precision=4,stream = fp)\n",
    "def get_data(path_to_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"Read in and clean data\n",
    "    Args:\n",
    "        path_to_csv (str): processed data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path_to_csv)[\n",
    "        ['category', 'headline', 'short_description', 'link']\n",
    "    ]\n",
    "    data = data.dropna(subset=['headline', 'short_description', 'link'])\n",
    "\n",
    "    data.link = data.link.apply(clean_link)\n",
    "    data.short_description = data.short_description \\\n",
    "        .apply(clean_short_description)\n",
    "    data.headline = data.headline.apply(clean_headline)\n",
    "\n",
    "    data['text'] = data.link + \" \" + data.short_description \\\n",
    "        + \" \" + data.headline\n",
    "    data['tokens'] = data.text.apply(tokenize)\n",
    "    return data\n",
    "```\n",
    "<br>\n",
    "\n",
    "**Create a function train_data()**\n",
    "```\n",
    "@profile(precision=4,stream = fp)\n",
    "def train_data(train,test):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "    min_df=50,\n",
    "    lowercase=False,\n",
    "    tokenizer=lambda x: x)\n",
    "                                    \n",
    "    svc = SVC()\n",
    "    svc.fit(vectorizer.fit_transform(train.tokens), train.category)\n",
    "    training_time = time.time()\n",
    "    y_pred = svc.predict(vectorizer.transform(test.tokens))\n",
    "    return svc, training_time, y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74524a72-b241-42a7-ae6a-b1e46fea3293",
   "metadata": {},
   "source": [
    "#### To run for stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8cfff6-87ce-4c49-9d45-0affffdeed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m memory_profiler \"../intelligent-indexing/src/run_benchmarks.py\" -l \"../intelligent-indexing/logs/stock_stock.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c461fd-0e04-42c2-bbce-c6c7824956fc",
   "metadata": {},
   "source": [
    "#### To run for IPEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba9188-e462-4d31-b7fa-389d0142d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m memory_profiler \"../intelligent-indexing/src/run_benchmarks.py\" -i -l \"../intelligent-indexing/logs/intel_intel.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc0092-87ea-44d7-b3e3-df5a177831d5",
   "metadata": {},
   "source": [
    "**NOTE** : To save log files at appropriate locations. Add  <br>\n",
    "**While profiling stock**\n",
    "```\n",
    "fp = open(\"./Memory_Profiler_Results/stock_ressults/stock_report.log\", \"w+\") ## For stock results\n",
    "```\n",
    "**While profiling intel extension**\n",
    "```\n",
    "fp = open(\"./Memory_Profiler_Results/ipex_ressults/ipex_report.log\", \"w+\") ## For ipex results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891727cc-58d1-4523-a2e0-46491353c7c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Example to use **mprof** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eeb23a-c283-40e8-9d07-6dc492a3db24",
   "metadata": {},
   "source": [
    "Use @profile decorator above the function you want to profile. <br> \n",
    "Here is a file **example1.py** with below code <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e2ab49-8b67-4a1c-ab2d-411fea34dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "import random\n",
    "\n",
    "@profile\n",
    "def random_number_generator():\n",
    "    arr1 = [random.randint(1,10) for i in range(100000)]\n",
    "    arr2 = [random.randint(1,10) for i in range(100000)]\n",
    "    arr3 = [arr1[i]+arr2[i] for i in range(100000)]\n",
    "    del arr1\n",
    "    del arr2\n",
    "    tot = sum(arr3)\n",
    "    del arr3\n",
    "    print(tot)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random_number_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d2c18-c003-4844-8534-80201a6c45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof run example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e269f6f-7de4-444d-82c3-74cb7c90e313",
   "metadata": {},
   "source": [
    "The above command will execute the script and generate the new file by name **mprofile_[current_datetime].dat**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84376b61-b786-492c-ac9f-c670103652a6",
   "metadata": {},
   "source": [
    "mprof command has different parameters\n",
    "- **--interval INTERVAL or -T INTERVAL** - As we had mentioned earlier, \"mprof\" records memory usage every \"0.1\" second by default. We can override this setting using this parameter. We can give time interval in seconds here.\n",
    "- **--timeout TIMEOUT or -t TIMEOUT** - By default, \"mprof\" monitors total execution of program/process. We can instruct it to stop monitoring after a specified amount of time using this parameter. It let us specify a time in seconds.\n",
    "- **--output FILENAME or -o FILENAME** - We can direct the result of profiling to an output file using this command. By default, \"mprof\" creates a file named \"mprofile_datetime.dat\". We can override that using this argument.\n",
    "- **--backend BACKEND** - This command let us specify backend for profiling. The default is \"psutil\" as we had mentioned a few times earlier. We would recommend users to stick to default as other backends do not seem reliable yet.\n",
    "- **--include-children** - It monitors memory usage across all children of process and shows their usage as one line chart.\n",
    "- **--multiprocess** - It generates a sample line chart for each sub-process and their memory usage per time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e95a0-b14b-4d42-908b-d519514d360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afdee9-d16d-4c3b-9e99-4a7a5de74e2a",
   "metadata": {},
   "source": [
    "mprof plot has different parameters like\n",
    "- **-o** :  To save plot to output file\n",
    "- **-t** : To give title to plot <br>\n",
    "It automatically takes the latest .dat file created by mprof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17d3db-47f3-4a62-bead-89995fc0c28c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Example to use **mprof** for **intelligent_indexing** ref kit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d3248e-d309-4272-babf-1738293e06da",
   "metadata": {},
   "source": [
    "Just add the **@profile** decorator at the top of functions you want to profile. <br>\n",
    "Modify the run_benchmarks.py file to add **@profile** decorators as shown in above example for **intelligent-indexing**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1ad7e-e057-4fe1-b241-ebd8a15c0def",
   "metadata": {},
   "source": [
    "#### To run for stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7611291-cc29-40af-b933-f375b330d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof run \"../intelligent-indexing/src/run_benchmarks.py\" -l \"../intelligent-indexing/logs/stock_stock.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e3599-ba33-4da0-bb44-f1a9f542f2ec",
   "metadata": {},
   "source": [
    "#### To run for IPEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8710d-7f68-4d67-ba57-ba44fc7fc485",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof run \"../intelligent-indexing/src/run_benchmarks.py\" -i -l \"../intelligent-indexing/logs/intel_intel.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78c3a7-5d06-4e75-939e-ddd8ce451721",
   "metadata": {},
   "source": [
    "**NOTE** : To save log files at appropriate locations. Add  <br>\n",
    "**While profiling stock**\n",
    "```\n",
    "fp = open(\"./Memory_Profiler_Results/stock_ressults/stock_report.log\", \"w+\") ## For stock results\n",
    "```\n",
    "**While profiling intel extension**\n",
    "```\n",
    "fp = open(\"./Memory_Profiler_Results/ipex_ressults/ipex_report.log\", \"w+\") ## For ipex results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f45bdd-d923-42d7-9b63-421dc11e2169",
   "metadata": {},
   "source": [
    "##### **To visaulize the plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb0e37-304f-49dd-9990-738dd26694fb",
   "metadata": {},
   "source": [
    "Go to the respective results folder and execute\n",
    "```\n",
    "!mprof plot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683483ae-0d00-4185-bc06-dfce14c69451",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Example to use **memory_usage()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beaddb0d-efb4-4712-8ecd-cdd248a9dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def very_slow_random_generator(sz=1000):\n",
    "    time.sleep(5)\n",
    "    arr1 = np.random.randint(1,100, size=(sz, sz))\n",
    "    avg = arr1.mean()\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c7d83-663b-419a-8c7a-ed322741ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage = memory_usage((very_slow_random_generator, (10000,), ), timestamps=True, interval=0.1,stream=open(\"example_memory_usage.txt\", \"w\"))\n",
    "mem_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd843c-b78b-40c2-b1cf-e9ad246e6d78",
   "metadata": {},
   "source": [
    "To Profile using **memory_usage**. We need one of the following\n",
    "- **Process**: We need to provide process id as an integer or string.\n",
    "- **Python Function**: The function followed by its arguments needs to be provided as a tuple. <br>\n",
    "\n",
    "In the above example we use\n",
    "- **Python function**: very_slow_random_generator\n",
    "- **interval**: 0.1 seconds\n",
    "- **timestamps**: True, will return the timestamps at which memory_usage was recorded\n",
    "- **stream**: To save results to output file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b4ae6-013d-43d0-abac-218823dddf85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. Example to use **mprun** and **memit** magic line commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20fa882-7377-4d7e-8822-656d1f53e236",
   "metadata": {},
   "source": [
    "The memory_profiler provides 2 line magic commands and 2 cell magic commands to be used in jupyter notebooks.\n",
    "\n",
    "- **Line Magic Commands**: %mprun & %memit\n",
    "- **Cell Magic Commands**: %%mprun & %%memit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a05581-4299-4517-8cdf-f66da83447d3",
   "metadata": {},
   "source": [
    "### Create an example.py with following code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ab64e-5045-43c6-b2ac-61cee3133a20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "```\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "@profile\n",
    "def very_slow_random_generator():\n",
    "    time.sleep(5)\n",
    "    arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "    avg = arr1.mean()\n",
    "    return avg\n",
    "\n",
    "@profile\n",
    "def slow_random_generator():\n",
    "    time.sleep(2)\n",
    "    arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "    avg = arr1.mean()\n",
    "    return avg\n",
    "\n",
    "@profile\n",
    "def main_func():\n",
    "    avg1 = slow_random_generator()\n",
    "    avg2 = very_slow_random_generator()\n",
    "\n",
    "    print(\"Averages: {:.3f}, {:.3f}\".format(avg1,avg2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_func()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af88c77-2d8f-4e9d-84b3-35bb88772f13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **%mprun** magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee26bb5-3bfd-4987-9406-6eeefbcb55c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from example import very_slow_random_generator,\\\n",
    "                                    slow_random_generator,\\\n",
    "                                    main_func\n",
    "\n",
    "%mprun -f very_slow_random_generator -T 'slow_profile_dump.log' -f slow_random_generator -f main_func main_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d5232-e72a-43d3-8231-c32b0dd5f7dd",
   "metadata": {},
   "source": [
    "**mprun** has following parameters\n",
    "- **-f**: To specify what functions to profile\n",
    "- **-T**: Specify after function to save results for that function at a particular path <br>\n",
    "\n",
    "\n",
    "In above example the **very_slow_random_generator**, **slow_random_generator**, **main_function** are profiled and results of **very_slow_random_generator** are saved to **slow_profile_dump.log**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc5f98-591e-4857-b038-d5d887366aa4",
   "metadata": {},
   "source": [
    "#### **%memit** Line Magic Command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426af4f-e862-4beb-8033-7800dbd3114f",
   "metadata": {},
   "source": [
    "The **%memit** cell command works for whole cell and reports **peak memory usage** of the whole cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c5d6f-2683-467d-b858-854b1dcd7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit very_slow_random_generator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
