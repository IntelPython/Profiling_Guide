{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1218fc0c-74fd-45fb-8526-9862dbc316dd",
   "metadata": {},
   "source": [
    "# Scalene Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a77d8-c4a7-4d01-8648-a95c23d1940c",
   "metadata": {},
   "source": [
    "**Scalene** is a high-performance CPU, GPU and memory profiler for Python that does a number of things that other Python profilers cannot do. It runs orders of magnitude faster than many other profilers while delivering detailed information. It is also the first profiler ever to incorporate **AI-powered proposed optimizations**. To enable these, you need to enter an **OpenAI key**. <br>\n",
    "Once a valid key is entered, click on the lightning bolt (âš¡) beside any line or the explosion (ðŸ’¥) for an entire region of code to generate a proposed optimization. Click on a proposed optimization to copy it to the clipboard. <br>\n",
    "Scalene can profile GPU workloads. It can profile individual threads. It provides memory consumption information. It does not provide call stack information. <br>\n",
    "To know more about Scalene visit its **[GitHub respository.](https://github.com/plasma-umass/scalene)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96886072-0b37-4fa4-9f4a-74dc2a5a5a3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To Install Scalene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72929fd5-de4d-4ed4-8b99-57cf5ac51659",
   "metadata": {},
   "source": [
    "**Note:** Please use scalene **version 1.3.12** for profiling **[Intelligent-Indexing](https://github.com/oneapi-src/intelligent-indexing)** toolkit explained below. <br>\n",
    "**Using pip**\n",
    "\n",
    "`pip install scalene==1.3.12`\n",
    "\n",
    "**For general installation** \n",
    "**Using pip**\n",
    "\n",
    "`python3 -m pip install -U scalene`\n",
    "\n",
    "**Using Conda**\n",
    "\n",
    "`conda install -c conda-forge scalene`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729ed30-bfbc-4937-bdd0-68a8e3e6a7ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ways to Profile Python Code Using Scalene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63180667-7d70-4379-8802-6f413d2d5686",
   "metadata": {},
   "source": [
    "- **1. Using scalene in CLI:** No code modification is required in this case.\n",
    "- **2. Using Scalene to profile only specific functions via @profile decorator:** Code modification is required in this case.\n",
    "\n",
    "**Web-based GUI** <br>\n",
    "Scalene has both a CLI and a web-based GUI **[demo here.](http://plasma-umass.org/scalene-gui/)** <br>\n",
    "\n",
    "By default, once Scalene has profiled your program, it will open a tab in a web browser with an interactive user interface (all processing is done locally). Hover over bars to see breakdowns of CPU and memory consumption, and click on underlined column headers to sort the columns. The generated file profile.html is self-contained and can be saved for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de3d7e-8472-4861-ab32-1036118eb938",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1: Using Scalene in CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c922779-7423-47cc-80bf-d5d27263150f",
   "metadata": {},
   "source": [
    "Create a python file **example1.py**  and **uncomment** the code. We have already created one for your reference, so you are free to skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ee04fb-74b5-4049-a285-7d75800f44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# def very_slow_random_generator():     ##Function to generate random number\n",
    "#     time.sleep(5)                     ## Added 5 secs sleep to simulate slow generator\n",
    "#     arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "#     avg = arr1.mean()\n",
    "#     return avg\n",
    "\n",
    "\n",
    "# def slow_random_generator():         ##Function to generate random number\n",
    "#     time.sleep(2)                    ## Added 2 secs sleep to simulate slow generator\n",
    "#     arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "#     avg = arr1.mean()\n",
    "#     return avg\n",
    "\n",
    "# def main_func():\n",
    "#     avg1 = slow_random_generator()\n",
    "#     avg2 = very_slow_random_generator()\n",
    "\n",
    "#     print(\"Averages: {:.3f}, {:.3f}\".format(avg1,avg2))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b4d92-7034-499f-866b-84ac14cb7446",
   "metadata": {},
   "source": [
    "To know more about how to use Scalene use **--help**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85a9077-e37e-46f7-873d-1d8c7b5fabe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: scalene \u001b[1m[\u001b[0m-h\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--version\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--column-width COLUMN_WIDTH\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--outfile OUTFILE\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--html\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--json\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--cli\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--stacks\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--web\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--viewer\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--reduced-profile\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--profile-interval PROFILE_INTERVAL\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--cpu\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--cpu-only\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--gpu\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--memory\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--profile-all\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--profile-only PROFILE_ONLY\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--profile-exclude PROFILE_EXCLUDE\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--use-virtual-time\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--cpu-percent-threshold CPU_PERCENT_THRESHOLD\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--cpu-sampling-rate CPU_SAMPLING_RATE\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--allocation-sampling-window ALLOCATION_SAMPLING_WINDOW\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--malloc-threshold MALLOC_THRESHOLD\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--program-path PROGRAM_PATH\u001b[1m]\u001b[0m \u001b[1m[\u001b[0m--memory-leak-detector\u001b[1m]\u001b[0m\n",
      "               \u001b[1m[\u001b[0m--on | --off\u001b[1m]\u001b[0m\n",
      "\n",
      "\u001b[1mScalene\u001b[0m: a high-precision CPU and memory profiler, version \u001b[1;92m1.5.21.2\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m2023.04\u001b[0m.\u001b[1;36m20\u001b[0m\u001b[1m)\u001b[0m\n",
      "\u001b]8;id=199721;https://github.com/plasma-umass/scalene\u001b\\\u001b[4;94mhttps://github.com/plasma-umass/scalene\u001b[0m\u001b]8;;\u001b\\\n",
      "\n",
      "command-line:\n",
      "  % \u001b[1mscalene \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\u001b[1m your_program.py \u001b[0m\u001b[1m[\u001b[0m\u001b[1m--- --your_program_args\u001b[0m\u001b[1m]\u001b[0m\u001b[1m \u001b[0m\n",
      "or\n",
      "  % \u001b[1mpython3 -m scalene \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\u001b[1m your_program.py \u001b[0m\u001b[1m[\u001b[0m\u001b[1m--- --your_program_args\u001b[0m\u001b[1m]\u001b[0m\u001b[1m \u001b[0m\n",
      "\n",
      "in Jupyter, line mode:\n",
      "\u001b[1m  %scrun \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\u001b[1m statement\u001b[0m\n",
      "\n",
      "in Jupyter, cell mode:\n",
      "\u001b[1m  %%scalene \u001b[0m\u001b[1m[\u001b[0m\u001b[1moptions\u001b[0m\u001b[1m]\u001b[0m\n",
      "\u001b[1m   your code here\u001b[0m\n",
      "\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             prints the version number for this release of Scalene \n",
      "and exits\n",
      "  --column-width COLUMN_WIDTH\n",
      "                        Column width for profile output \u001b[1m(\u001b[0mdefault: \u001b[1;34m132\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --outfile OUTFILE     file to hold profiler output \u001b[1m(\u001b[0mdefault: \u001b[34mstdout\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --html                output as HTML \u001b[1m(\u001b[0mdefault: \u001b[34mweb\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --json                output as JSON \u001b[1m(\u001b[0mdefault: \u001b[34mweb\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --cli                 forces use of the command-line\n",
      "  --stacks              collect stack traces\n",
      "  --web                 opens a web tab to view the profile \u001b[1m(\u001b[0msaved as \n",
      "\u001b[32m'profile.html'\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --viewer              only opens the web UI \n",
      "\u001b[1m(\u001b[0m\u001b[4;94mhttps://plasma-umass.org/scalene-gui/\u001b[0m\u001b[4;94m)\u001b[0m\n",
      "  --reduced-profile     generate a reduced profile, with non-zero lines only \n",
      "\u001b[1m(\u001b[0mdefault: \u001b[3;34mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --profile-interval PROFILE_INTERVAL\n",
      "                        output profiles every so many seconds \u001b[1m(\u001b[0mdefault: \u001b[34minf\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --cpu                 profile CPU time \u001b[1m(\u001b[0mdefault: \u001b[34m \u001b[0m\u001b[3;34mTrue\u001b[0m\u001b[34m \u001b[0m\u001b[1m)\u001b[0m\n",
      "  --cpu-only            profile CPU time \u001b[1m(\u001b[0m\u001b[31mdeprecated: use --cpu \u001b[0m\u001b[1m)\u001b[0m\n",
      "  --gpu                 profile GPU time and memory \u001b[1m(\u001b[0mdefault: \u001b[3;34mTrue\u001b[0m\u001b[34m \u001b[0m\u001b[1m)\u001b[0m\n",
      "  --memory              profile memory \u001b[1m(\u001b[0mdefault: \u001b[3;34mTrue\u001b[0m\u001b[34m \u001b[0m\u001b[1m)\u001b[0m\n",
      "  --profile-all         profile all executed code, not just the target program \n",
      "\u001b[1m(\u001b[0mdefault: \u001b[34monly the target program\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --profile-only PROFILE_ONLY\n",
      "                        profile only code in filenames that contain the given \n",
      "strings, separated by commas \u001b[1m(\u001b[0mdefault: \u001b[34mno restrictions\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --profile-exclude PROFILE_EXCLUDE\n",
      "                        do not profile code in filenames that contain the given \n",
      "strings, separated by commas \u001b[1m(\u001b[0mdefault: \u001b[34mno restrictions\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --use-virtual-time    measure only CPU time, not time spent in I/O or blocking\n",
      "\u001b[1m(\u001b[0mdefault: \u001b[3;34mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --cpu-percent-threshold CPU_PERCENT_THRESHOLD\n",
      "                        only report profiles with at least this percent of CPU \n",
      "time \u001b[1m(\u001b[0mdefault: \u001b[1;34m1\u001b[0m\u001b[34m%\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --cpu-sampling-rate CPU_SAMPLING_RATE\n",
      "                        CPU sampling rate \u001b[1m(\u001b[0mdefault: every \u001b[1;34m0.\u001b[0m\u001b[34m01s\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --allocation-sampling-window ALLOCATION_SAMPLING_WINDOW\n",
      "                        Allocation sampling window size, in bytes \u001b[1m(\u001b[0mdefault: \n",
      "\u001b[1;34m10485767\u001b[0m\u001b[34m bytes\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --malloc-threshold MALLOC_THRESHOLD\n",
      "                        only report profiles with at least this many allocations\n",
      "\u001b[1m(\u001b[0mdefault: \u001b[1;34m100\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --program-path PROGRAM_PATH\n",
      "                        The directory containing the code to profile \u001b[1m(\u001b[0mdefault: \n",
      "\u001b[34mthe path to the profiled program\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --memory-leak-detector\n",
      "                        EXPERIMENTAL: report likely memory leaks \u001b[1m(\u001b[0mdefault: \u001b[3;34mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
      "  --on                  start with profiling on \u001b[1m(\u001b[0mdefault\u001b[1m)\u001b[0m\n",
      "  --off                 start with profiling off\n",
      "\n",
      "When running Scalene in the background, you can suspend/resume profiling\n",
      "for the process ID that Scalene reports. For example:\n",
      "\n",
      "   % python3 -m scalene  yourprogram.py &\n",
      " Scalene now profiling process \u001b[1;36m12345\u001b[0m\n",
      "   to suspend profiling: python3 -m scalene.profile --off --pid \u001b[1;36m12345\u001b[0m\n",
      "   to resume profiling:  python3 -m scalene.profile --on  --pid \u001b[1;36m12345\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!scalene --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbcf120-613f-431c-9748-6e385a584e15",
   "metadata": {},
   "source": [
    "Execute the below line to profile **example1.py** using **Scalene**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb72932-7d79-4342-a441-2be4112841d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages: 49.945, 50.002\n"
     ]
    }
   ],
   "source": [
    "!scalene --html --outfile example1_output.html example1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dace7b6-b344-4396-a362-8cc3ceb49c3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Scalene Example1 Results Interpretation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e7d3f-5eb0-48e7-92f1-fdd51d18caf7",
   "metadata": {},
   "source": [
    "While in the jupyter notebook click the `example1_output.html` file. It will open a new tab. \n",
    "\n",
    "The result has the following columns\n",
    "\n",
    "- **Memory usage:** At the top, visualized by \"sparklines\", memory consumption over the runtime of the profiled code. <br>\n",
    "- **Time Python:** How much time was spent in Python code.\n",
    "- **native:** How much time was spent in non-Python code (e.g., libraries written in C/C++).\n",
    "- **system:** How much time was spent in the system (e.g., I/O).\n",
    "- **GPU:** (not shown here) How much time spent on the GPU, if your system has an NVIDIA GPU installed.\n",
    "- **Memory Python:** How much of the memory allocation happened on the Python side of the code, as opposed to in non-Python code (e.g., libraries written in C/C++).\n",
    "- **net:** Positive net memory numbers indicate total memory allocation in megabytes; negative net memory numbers indicate memory reclamation.\n",
    "- **timeline / %:** Visualized by \"sparklines\", memory consumption generated by this line over the program runtime, and the percentages of total memory activity this line represents.\n",
    "- **Copy (MB/s):** The amount of megabytes being copied per second (see \"About Scalene\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1fc58-58db-4e5e-b129-4870ab0f862f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Using Scalene to profile specific functions in Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a111d77-a0f4-4080-a855-4a2247b8e3f4",
   "metadata": {},
   "source": [
    "Create a python file **example2.py**  and **uncomment** the code. We have already created one for your reference, so you are free to skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb04454-d277-4b93-95ce-3c5614cf5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# @profile                            ## Add @profile decorator to profile function\n",
    "# def very_slow_random_generator():   ##Function to generate random number\n",
    "#     time.sleep(5)                   ##Added 5 sec sleep to simulate slow generator\n",
    "#     arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "#     avg = arr1.mean()\n",
    "#     return avg\n",
    "\n",
    "# @profile                           ## Add @profile decorator to profile function\n",
    "# def slow_random_generator():       ##Function to generate random number\n",
    "#     time.sleep(2)                  ##Added 2 sec sleep to simulate slow generator\n",
    "#     arr1 = np.random.randint(1,100, size=(1000,1000))\n",
    "#     avg = arr1.mean()\n",
    "#     return avg\n",
    "\n",
    "# def main_func():\n",
    "#     avg1 = slow_random_generator()\n",
    "#     avg2 = very_slow_random_generator()\n",
    "#     print(\"Averages: {:.3f}, {:.3f}\".format(avg1,avg2))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e9994-1001-4231-b994-ab8c40e6bdeb",
   "metadata": {},
   "source": [
    "Execute the below line to profile **example2.py** using **Scalene**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ed75d3-8964-4857-9e94-ed49bf889a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages: 49.983, 49.998\n"
     ]
    }
   ],
   "source": [
    "!scalene --html --outfile example2_output.html example2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312a31a-e7c3-432e-ad66-df8deb7cb34e",
   "metadata": {},
   "source": [
    "While in the jupyter notebook click the `example2_output.html` file. It will open a new tab. \n",
    "\n",
    "The result has the following columns\n",
    "\n",
    "- **Memory usage:** At the top, visualized by \"sparklines\", memory consumption over the runtime of the profiled code. <br>\n",
    "- **Time Python:** How much time was spent in Python code.\n",
    "- **native:** How much time was spent in non-Python code (e.g., libraries written in C/C++).\n",
    "- **system:** How much time was spent in the system (e.g., I/O).\n",
    "- **GPU:** (not shown here) How much time spent on the GPU, if your system has an NVIDIA GPU installed.\n",
    "- **Memory Python:** How much of the memory allocation happened on the Python side of the code, as opposed to in non-Python code (e.g., libraries written in C/C++).\n",
    "- **net:** Positive net memory numbers indicate total memory allocation in megabytes; negative net memory numbers indicate memory reclamation.\n",
    "- **timeline / %:** Visualized by \"sparklines\", memory consumption generated by this line over the program runtime, and the percentages of total memory activity this line represents.\n",
    "- **Copy (MB/s):** The amount of megabytes being copied per second (see \"About Scalene\").\n",
    "\n",
    "There is no difference in the results from **example1** and **example2**. In **example2** we can choose what functions we want to profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709a170-5655-44a7-902a-431ad2637bbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using **Scalene** for **intelligent_indexing** ref kit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96f2a9-15f6-4d9b-9f45-ac68690a2a97",
   "metadata": {},
   "source": [
    "The **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** ref kit demonstrates one way of building an NLP pipeline for classifying documents to their respective topics and describe how we can leverage the **IntelÂ® AI Analytics Toolkit (AI Kit)** to accelerate the pipeline.\n",
    "\n",
    "**IntelÂ® AI Analytics Toolkit (AI Kit)** is used to achieve quick results even when the data for a model are huge. It provides the capability to reuse the code present in different languages so that the hardware utilization is optimized to provide these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69f9be-fcba-43df-baea-19557571a996",
   "metadata": {},
   "source": [
    "The **Intelligent Indexing** ref kit has different IntelÂ® oneAPI optimizations enabled like:\n",
    "- **[IntelÂ® Distribution of Modin*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-of-modin.html#gs.v03x2l)**\n",
    "The IntelÂ® Distribution of Modin* is a performant, parallel, and distributed dataframe system that is designed around enabling data scientists to be more productive. It provides drop-in acceleration to your existing **pandas** workflows. No upfront cost to learning a new API. Integrates with the Python* ecosystem. Seamlessly scales across multicores with Ray* and Dask* clusters (run on and with what you have)\n",
    "- **[IntelÂ® Extension for Scikit-learn*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/scikit-learn.html)**\n",
    "Designed for data scientists, IntelÂ® Extension for Scikit-Learn* is a seamless way to speed up your Scikit-learn applications for machine learning to solve real-world problems. This extension package dynamically patches scikit-learn estimators to use IntelÂ® oneAPI Data Analytics Library (oneDAL) as the underlying solver, while achieving the speed up for your machine learning algorithms out-of-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5495d6-068d-455f-a37a-1d6ca668ce75",
   "metadata": {},
   "source": [
    "**NOTE** Please visit the **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** Ref kit page to know more about the kit.\n",
    "- Please follow the steps in github repo to clone and create the environment.\n",
    "- After creating environment install **scalene** in both the environments **doc_class_stock** and **doc_class_intel** using\n",
    "\n",
    "`pip install scalene==1.3.12`\n",
    "\n",
    "We will be using **scalene** to profile this workload below. Please note that IntelÂ® Distribution of Modin* will be disabled for this profiling, and Scalene does not currently support IntelÂ® Distribution of Modin* with Ray* backend, which is used in the Intelligent Indexing ref kit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b0df4-839a-413f-806c-6d2b3c349f35",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Modify the run_benchmarks.py File of the Reference Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc9f2c-4a6e-47dd-9de6-786954e5acad",
   "metadata": {},
   "source": [
    "Just add the **@profile** decorator at the top of functions you want to profile. <br>\n",
    "\n",
    "Modify the **run_benchmarks.py (Location '../intelligent-indexing/src/run_benchmarks.py')** file to add **@profile** decorators as shown below (we have provided a **run_benchmarks_scalene.py** for your reference, **copy the file at Location '../intelligent-indexing/src/run_benchmarks_scalene.py'**, if you would like to skip this step and move to the next section). <br>\n",
    "\n",
    "**Modify the get_data() function**\n",
    "```\n",
    "@profile\n",
    "def get_data(path_to_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"Read in and clean data\n",
    "    Args:\n",
    "        path_to_csv (str): processed data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path_to_csv)[\n",
    "        ['category', 'headline', 'short_description', 'link']\n",
    "    ]\n",
    "    data = data.dropna(subset=['headline', 'short_description', 'link'])\n",
    "\n",
    "    data.link = data.link.apply(clean_link)\n",
    "    data.short_description = data.short_description \\\n",
    "        .apply(clean_short_description)\n",
    "    data.headline = data.headline.apply(clean_headline)\n",
    "\n",
    "    data['text'] = data.link + \" \" + data.short_description \\\n",
    "        + \" \" + data.headline\n",
    "    data['tokens'] = data.text.apply(tokenize)\n",
    "    return data\n",
    "```\n",
    "<br>\n",
    "\n",
    "**Create a function train_data()**\n",
    "```\n",
    "@profile\n",
    "def train_data(train,test):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "    min_df=50,\n",
    "    lowercase=False,\n",
    "    tokenizer=lambda x: x)\n",
    "                                    \n",
    "    svc = SVC()\n",
    "    svc.fit(vectorizer.fit_transform(train.tokens), train.category)\n",
    "    training_time = time.time()\n",
    "    y_pred = svc.predict(vectorizer.transform(test.tokens))\n",
    "    return svc, training_time, y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e599e7-3a17-4266-b07c-b196ccd7d909",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9c70a-78c1-4b93-8979-91ea10fa8b0a",
   "metadata": {},
   "source": [
    "To ignore warnings run the below cell and if the result directories are not present uncomment the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc0598-089f-4030-a4d1-4bcb22b6192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# mkdir -p Scalene_Profiler_Results  # create `Scalene_Profiler_Results` dir in the parent dir if not present\n",
    "# mkdir -p Scalene_Profiler_Results/stock_results  # create `stock_results` dir in the Scalene_Profiler_Results if not present\n",
    "# mkdir -p Scalene_Profiler_Results/oneapi_optimized_results  # create `oneapi_optimized_results` dir in the Scalene_Profiler_Results if not present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1cf849-95fc-4df3-93b5-a7a183f1b2ee",
   "metadata": {},
   "source": [
    "**Ensure that you have run_benchmarks_scalene.py file**<br>\n",
    "To run the profiler on the intelligent indexing ref kit <br>\n",
    "1. Navigate to directory **intelligent-indexing/src/** in terminal <br>\n",
    "`conda activate doc_class_stock`\n",
    "\n",
    "Execute the below command in Terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15590022-612e-48c5-b63c-b23a5cf8ee26",
   "metadata": {},
   "source": [
    "`scalene --html --outfile ../../Profiling_Guide/Scalene_Profiler/Scalene_Profiler_Results/stock_results/scalene_stock.html  run_benchmarks_scalene.py -l ../logs/stock_stock.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0daed0-1aad-4e7f-87e7-656680e373cb",
   "metadata": {},
   "source": [
    "**To visualize the results**, go to the **Scalene_Profiler_Results/stock_results** directory and being in the jupyter notebook open the file **scalene_stock.html**. <br>\n",
    "The result has the following columns <br>\n",
    "- **Memory usage:** At the top, visualized by \"sparklines\", memory consumption over the runtime of the profiled code. <br>\n",
    "- **Time Python:** How much time was spent in Python code.\n",
    "- **native:** How much time was spent in non-Python code (e.g., libraries written in C/C++).\n",
    "- **system:** How much time was spent in the system (e.g., I/O).\n",
    "- **GPU:** (not shown here) How much time spent on the GPU, if your system has an NVIDIA GPU installed.\n",
    "- **Memory Python:** How much of the memory allocation happened on the Python side of the code, as opposed to in non-Python code (e.g., libraries written in C/C++).\n",
    "- **net:** Positive net memory numbers indicate total memory allocation in megabytes; negative net memory numbers indicate memory reclamation.\n",
    "- **timeline / %:** Visualized by \"sparklines\", memory consumption generated by this line over the program runtime, and the percentages of total memory activity this line represents.\n",
    "- **Copy (MB/s):** The amount of megabytes being copied per second (see \"About Scalene\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e67e3-bb47-4bd0-887d-8400f98f92b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Intel oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97075250-6b72-414b-b729-4abcf8a574f5",
   "metadata": {},
   "source": [
    "**Ensure that you have run_benchmarks_scalene.py file.** <br>\n",
    "To run the profiler on the intelligent indexing ref kit <br>\n",
    "1. Navigate to directory **intelligent-indexing/src/** in terminal <br>\n",
    "`conda activate doc_class_intel`\n",
    "\n",
    "Execute the below command in Terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2e8bf-3a0a-4ba5-9563-bf607ef2dbc8",
   "metadata": {},
   "source": [
    "`scalene --html --outfile ../../Profiling_Guide/Scalene_Profiler/Scalene_Profiler_Results/oneapi_optimized_results/scalene_intel.html run_benchmarks_scalene.py -i -l ../logs/intel_intel.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9998212a-f857-43a6-9f20-34442b0112fb",
   "metadata": {},
   "source": [
    "**To visualize the results**, go to the **Scalene_Profiler_Results/oneapi_optimized_results** directory and being in the jupyter notebook open the file **scalene_intel.html**. <br>\n",
    "The result has the following columns <br>\n",
    "- **Memory usage:** At the top, visualized by \"sparklines\", memory consumption over the runtime of the profiled code. <br>\n",
    "- **Time Python:** How much time was spent in Python code.\n",
    "- **native:** How much time was spent in non-Python code (e.g., libraries written in C/C++).\n",
    "- **system:** How much time was spent in the system (e.g., I/O).\n",
    "- **GPU:** (not shown here) How much time spent on the GPU, if your system has an NVIDIA GPU installed.\n",
    "- **Memory Python:** How much of the memory allocation happened on the Python side of the code, as opposed to in non-Python code (e.g., libraries written in C/C++).\n",
    "- **net:** Positive net memory numbers indicate total memory allocation in megabytes; negative net memory numbers indicate memory reclamation.\n",
    "- **timeline / %:** Visualized by \"sparklines\", memory consumption generated by this line over the program runtime, and the percentages of total memory activity this line represents.\n",
    "- **Copy (MB/s):** The amount of megabytes being copied per second (see \"About Scalene\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
