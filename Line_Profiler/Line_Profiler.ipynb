{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6564ad7-2463-4f7d-a9e1-3dcb6d9b666c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Line Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf283e-b70a-43be-a454-00fb75f0214c",
   "metadata": {},
   "source": [
    "Function profiling tools only time function calls. This is a good first step for locating hotspots in one's program and is frequently all one needs to do to optimize the program. **However, sometimes the cause of the hotspot is actually a single line in the function, and that line may not be obvious from just reading the source code**. These cases are particularly frequent in scientific computing. Functions tend to be larger (sometimes because of legitimate algorithmic complexity), and a single statement without function calls can trigger lots of computation when using libraries like NumPy. cProfile only times explicit function calls, not special methods called because of syntax. Consequently, a relatively slow numpy operation on large arrays like this,\n",
    "```\n",
    "a[large_index_array] = some_other_large_array\n",
    "```\n",
    "is a hotspot that never gets broken out by cProfile because there is no explicit function call in that statement.\n",
    "\n",
    "***LineProfiler can be given functions to profile, and it will time the execution of each individual line inside those functions.*** <br>\n",
    "\n",
    "To know more about the line profiler please visit the [line profiler documentation](https://github.com/pyutils/line_profiler) <br>\n",
    "\n",
    "### To Install line_profiler** \n",
    "**Using Conda**\n",
    "`conda install line_profiler`\n",
    "\n",
    "**Using pip**\n",
    "\n",
    "`pip install line_profiler`\n",
    "\n",
    "To install compatible IPython version using pip:\n",
    "\n",
    "`pip install line_profiler[ipython]`\n",
    "\n",
    "To check out the development sources, you can use Git:\n",
    "\n",
    "`git clone https://github.com/pyutils/line_profiler.git`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09af3c0-bfc5-4575-8521-9c9df335ce96",
   "metadata": {},
   "source": [
    "### Ways to Profile Python Code using **line_profiler**\n",
    "- **kernprof**: Command Prompt/Shell Command: This command let us profile whole Python script from command line/shell.\n",
    "- **LineProfiler**: Object in Python Script: This let us profile individual functions of our code by declaring profiler object in script itself.\n",
    "- **%lprun**: Jupyter Notebook Magic Command: This let us profile functions in Jupyter Notebooks using \"%lprun\" line magic command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f8c06-62fc-4f84-904a-fda323a54f03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example to use KernProf and Line_Profiler Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eeb993-bdc5-49aa-bf18-ce61faf9ea09",
   "metadata": {},
   "source": [
    "Create a python file **random_number_average.py**  and **uncomment** the code. We have already created one for your reference, so you are free to skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4a0ee-0227-48d8-8df6-1f24400cf10d",
   "metadata": {},
   "source": [
    "**can you comment the code below with what is happening? high-level details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a27379f-915f-4a6d-9991-552a42e9a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import random\n",
    "\n",
    "# @profile\n",
    "# def very_slow_random_generator():\n",
    "#     time.sleep(5)\n",
    "#     arr = [random.randint(1,100) for i in range(100000)]\n",
    "#     return sum(arr) / len(arr)\n",
    "\n",
    "# @profile\n",
    "# def slow_random_generator():\n",
    "#     time.sleep(2)\n",
    "#     arr = [random.randint(1,100) for i in range(100000)]\n",
    "#     return sum(arr) / len(arr)\n",
    "    \n",
    "# @profile\n",
    "# def main_func():\n",
    "#     result = slow_random_generator()\n",
    "#     print(result)\n",
    "\n",
    "#     result = very_slow_random_generator()\n",
    "#     print(result)\n",
    "\n",
    "# main_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157d66e-3cfc-432b-b6f9-158d8560237f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### KernProf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf005436-108d-486a-8432-6c654962ede4",
   "metadata": {},
   "source": [
    "To Profile this file use decorators **@profile** above the function use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9bc1b9-43bf-476a-ba36-2967fa547abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.46538\n",
      "50.52094\n",
      "Wrote profile results to random_number_average.py.lprof\n"
     ]
    }
   ],
   "source": [
    "!kernprof -l random_number_average.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e794d2-a042-4cdd-97fc-d6550fbfdee0",
   "metadata": {},
   "source": [
    "To see **output** from the above file, use the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40303d53-1a0b-415d-b9b0-4db1130ed3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 5.2137 s\n",
      "File: random_number_average.py\n",
      "Function: very_slow_random_generator at line 4\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     4                                           @profile\n",
      "     5                                           def very_slow_random_generator():\n",
      "     6         1    5005141.8 5005141.8     96.0      time.sleep(5)\n",
      "     7         1     207910.0 207910.0      4.0      arr = [random.randint(1,100) for i in range(100000)]\n",
      "     8         1        649.2    649.2      0.0      return sum(arr) / len(arr)\n",
      "\n",
      "Total time: 2.21464 s\n",
      "File: random_number_average.py\n",
      "Function: slow_random_generator at line 10\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    10                                           @profile\n",
      "    11                                           def slow_random_generator():\n",
      "    12         1    2002103.7 2002103.7     90.4      time.sleep(2)\n",
      "    13         1     211889.0 211889.0      9.6      arr = [random.randint(1,100) for i in range(100000)]\n",
      "    14         1        647.4    647.4      0.0      return sum(arr) / len(arr)\n",
      "\n",
      "Total time: 7.42858 s\n",
      "File: random_number_average.py\n",
      "Function: main_func at line 16\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    16                                           @profile\n",
      "    17                                           def main_func():\n",
      "    18         1    2214732.9 2214732.9     29.8      result = slow_random_generator()\n",
      "    19         1         28.8     28.8      0.0      print(result)\n",
      "    20                                           \n",
      "    21         1    5213789.1 5213789.1     70.2      result = very_slow_random_generator()\n",
      "    22         1         27.4     27.4      0.0      print(result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m line_profiler random_number_average.py.lprof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4bcd56-19b4-41a0-8d82-ffd69efcdfc7",
   "metadata": {},
   "source": [
    "To understand the results above, the different column definitions are given below\n",
    "- **Hits:** The first column represents number of times that line was hit inside that function. In our example hits it is 1 but it can be more than one in case of recurrences.\n",
    "- **Time:** The second column represents the time taken by that line in total for all hits. This time is in microseconds.\n",
    "- **Per Hit:** The third column represents time taken per each call of that line.\n",
    "- **% Time:** The fourth column represents % of time taken by that line of total function time.\n",
    "- **Line Contents:** The fifth column represents code in that line of function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d636de3-1078-4b56-9e8d-701126526111",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Line Profiler Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84f4fc-7df9-4d38-94e4-42932810d834",
   "metadata": {},
   "source": [
    "We then need to create an **object of LineProfiler class** first. We then need to create a wrapper around main_func() by calling the LineProfiler instance passing it main_func. We can then execute that line profiler wrapper which will execute main_func()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1947dde-13f0-495f-be53-92ffca6318bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can add this code in your **random_number_average.py?** Python file. However, we have an example file with the name **random_number_average_with_lp_object.py** already created for you, so feel free to skip this step. To add multiple functions to the LineProfiler object class, use the **add_function** method shown below.\n",
    "\n",
    "**can you comment the code below with what is happening?**\n",
    "```\n",
    "from line_profiler import LineProfiler\n",
    "\n",
    "lprofiler = LineProfiler()\n",
    "\n",
    "lprofiler.add_function(very_slow_random_generator)\n",
    "lprofiler.add_function(slow_random_generator)\n",
    "\n",
    "lp_wrapper = lprofiler(main_func)\n",
    "\n",
    "lp_wrapper()\n",
    "\n",
    "lprofiler.print_stats()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc58a90-ba7e-4aa8-854c-4d5d8f313a0c",
   "metadata": {},
   "source": [
    "We have an example file with the name **random_number_average_with_lp_object.py** already created for you. To view the results run the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e419bea-dcf4-445e-97be-4a0c19fe86e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.4126\n",
      "50.53084\n",
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 5.21065 s\n",
      "File: /home/u178155/yash_tests/Profiling_Guide/Line_Profiler/random_number_average_with_lp_object.py\n",
      "Function: very_slow_random_generator at line 6\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     6                                           def very_slow_random_generator():\n",
      "     7         1 5005105234.0 5005105234.0     96.1      time.sleep(5)\n",
      "     8         1  204900315.0 204900315.0      3.9      arr = [random.randint(1,100) for i in range(100000)]\n",
      "     9         1     645843.0 645843.0      0.0      return sum(arr) / len(arr)\n",
      "\n",
      "Total time: 2.21203 s\n",
      "File: /home/u178155/yash_tests/Profiling_Guide/Line_Profiler/random_number_average_with_lp_object.py\n",
      "Function: slow_random_generator at line 11\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    11                                           def slow_random_generator():\n",
      "    12         1 2002091765.0 2002091765.0     90.5      time.sleep(2)\n",
      "    13         1  209286096.0 209286096.0      9.5      arr = [random.randint(1,100) for i in range(100000)]\n",
      "    14         1     650456.0 650456.0      0.0      return sum(arr) / len(arr)\n",
      "\n",
      "Total time: 7.42289 s\n",
      "File: /home/u178155/yash_tests/Profiling_Guide/Line_Profiler/random_number_average_with_lp_object.py\n",
      "Function: main_func at line 16\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    16                                           def main_func():\n",
      "    17         1 2212108755.0 2212108755.0     29.8      result = slow_random_generator()\n",
      "    18         1      32737.0  32737.0      0.0      print(result)\n",
      "    19                                           \n",
      "    20         1 5210726637.0 5210726637.0     70.2      result = very_slow_random_generator()\n",
      "    21         1      25445.0  25445.0      0.0      print(result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python random_number_average_with_lp_object.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3de7e-a238-4ea4-a308-8dc2bdd643e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Profile the [Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing) Ref kit using Line Profiler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0020a2-34f8-43d4-b9f5-0c174eecc4c7",
   "metadata": {},
   "source": [
    "The **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** ref kit demonstrates one way of building an NLP pipeline for classifying documents to their respective topics and describe how we can leverage the **Intel® AI Analytics Toolkit (AI Kit)** to accelerate the pipeline.\n",
    "\n",
    "**Intel® AI Analytics Toolkit (AI Kit)** is used to achieve quick results even when the data for a model are huge. It provides the capability to reuse the code present in different languages so that the hardware utilization is optimized to provide these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b545dd0-f3f2-409a-a018-ed04afdbcbc7",
   "metadata": {},
   "source": [
    "The **Intelligent Indexing** ref kit has different Intel® oneAPI optimizations enabled like:\n",
    "- **[Intel® Distribution of Modin*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-of-modin.html#gs.v03x2l)**\n",
    "The Intel® Distribution of Modin* is a performant, parallel, and distributed dataframe system that is designed around enabling data scientists to be more productive. It provides drop-in acceleration to your existing **pandas** workflows. No upfront cost to learning a new API. Integrates with the Python* ecosystem. Seamlessly scales across multicores with Ray* and Dask* clusters (run on and with what you have)\n",
    "- **[Intel® Extension for Scikit-learn*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/scikit-learn.html)**\n",
    "Designed for data scientists, Intel® Extension for Scikit-Learn* is a seamless way to speed up your Scikit-learn applications for machine learning to solve real-world problems. This extension package dynamically patches scikit-learn estimators to use Intel® oneAPI Data Analytics Library (oneDAL) as the underlying solver, while achieving the speed up for your machine learning algorithms out-of-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41287718-310e-40ad-b29f-53915cfffc00",
   "metadata": {},
   "source": [
    "**NOTE** Please visit the **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** Ref kit page to know more about the kit.\n",
    "- Please follow the steps in github repo to clone and create the environment.\n",
    "- After creating environment install **line_profiler** in both the environments **doc_class_stock** and **doc_class_intel** using\n",
    "```\n",
    "conda install line_profiler\n",
    "```\n",
    "We will be using **line_profiler** to profile this workload below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91947908-a3bb-4222-8249-a5480b9d708f",
   "metadata": {},
   "source": [
    "Just add the **@profile** decorator at the top of functions you want to profile. <br>\n",
    "\n",
    "Modify the **run_benchmarks.py (Location '../intelligent-indexing/src/run_benchmarks.py')** file to add **@profile** decorators as shown below (we have provided a **run_benchmarks_modified.py** for your reference, if you would like to skip this step and move to the next section). <br>\n",
    "\n",
    "**Modify the get_data() function**\n",
    "```\n",
    "@profile\n",
    "def get_data(path_to_csv: str) -> pd.DataFrame:\n",
    "    \"\"\"Read in and clean data\n",
    "    Args:\n",
    "        path_to_csv (str): processed data\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path_to_csv)[\n",
    "        ['category', 'headline', 'short_description', 'link']\n",
    "    ]\n",
    "    data = data.dropna(subset=['headline', 'short_description', 'link'])\n",
    "\n",
    "    data.link = data.link.apply(clean_link)\n",
    "    data.short_description = data.short_description \\\n",
    "        .apply(clean_short_description)\n",
    "    data.headline = data.headline.apply(clean_headline)\n",
    "\n",
    "    data['text'] = data.link + \" \" + data.short_description \\\n",
    "        + \" \" + data.headline\n",
    "    data['tokens'] = data.text.apply(tokenize)\n",
    "    return data\n",
    "```\n",
    "<br>\n",
    "\n",
    "**Create a function train_data()**\n",
    "```\n",
    "@profile\n",
    "def train_data(train,test):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "    min_df=50,\n",
    "    lowercase=False,\n",
    "    tokenizer=lambda x: x)\n",
    "                                    \n",
    "    svc = SVC()\n",
    "    svc.fit(vectorizer.fit_transform(train.tokens), train.category)\n",
    "    training_time = time.time()\n",
    "    y_pred = svc.predict(vectorizer.transform(test.tokens))\n",
    "    return svc, training_time, y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99e1ae-b237-433b-b154-7909c5582581",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Profile the Intelligent Indexing Ref Kit with Stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249acf83-5cfa-4d81-9bd3-ab5cb4121219",
   "metadata": {},
   "source": [
    "To run the profiler on the intelligent indexing ref kit with stock, unoptimized packages: <br>\n",
    "- Navigate to directory **intelligent-indexing/src/** in terminal\n",
    "- `conda activate doc_class_stock`\n",
    "\n",
    "Execute the below command in Terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873e4cc-bdba-4af8-9d71-cd20beb6b007",
   "metadata": {},
   "source": [
    "`kernprof -l -o '../../Profiling_Guide/Line_Profiler/Line_Profiler_results/stock_results/line_stock.txt' run_benchmarks.py -l ../logs/stock_stock.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c280a-8421-4e15-8921-814e83037524",
   "metadata": {},
   "source": [
    "To visualize the results execute the below command from the **/intelligent-indexing/src/** directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75bfd24-cf34-443a-937d-79e37c9ed1f6",
   "metadata": {},
   "source": [
    "`python -m line_profiler '../../Profiling_Guide/Line_Profiler/Line_Profiler_results/stock_results/line_stock.txt'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a36db-8fbe-4dc7-beac-fd0d61c4642a",
   "metadata": {},
   "source": [
    "You can also save the profiling stats using flag **-o** as fname.prof and then use **snakeviz** to visualize the profiling results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43df83f8-e438-459e-8c50-d3639a274b65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Profile the Intelligent Indexing Ref Kit with Intel optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33d1b3-3b8b-4927-9509-4b9e9931d035",
   "metadata": {},
   "source": [
    "To run the profiler on the intelligent indexing ref kit with Intel optimized packages <br>\n",
    "- Navigate to directory **intelligent-indexing/src/** in terminal\n",
    "- `conda activate doc_class_intel`\\\n",
    "\n",
    "Execute the below command in Terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d136dd-54a1-4d4c-b344-6c36fd27e889",
   "metadata": {},
   "source": [
    "`kernprof -l -o '../../Profiling_Guide/Line_Profiler/Line_Profiler_results/oneapi_optimized_results/line_intel.txt' run_benchmarks.py -i -l ../logs/intel_intel.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32dbab-1088-46dd-adab-4fba6f40e2bb",
   "metadata": {},
   "source": [
    "To visualize the results execute the below command from the **intelligent-indexing/src/** directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d942ca-5f2e-4c81-a9ec-4dc2069a3192",
   "metadata": {},
   "source": [
    "`python -m line_profiler '../../Profiling_Guide/Line_Profiler/Line_Profiler_results/oneapi_optimized_results/line_intel.txt'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af5d69d-242c-4e8d-836f-568b0732df53",
   "metadata": {},
   "source": [
    "You can also save the profiling stats using flag **-o** as fname.prof and then use **snakeviz** to visualize the profiling results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_class_stock",
   "language": "python",
   "name": "doc_class_stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
