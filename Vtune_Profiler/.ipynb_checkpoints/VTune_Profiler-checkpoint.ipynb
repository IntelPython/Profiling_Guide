{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1688bc9-27e3-4728-abc9-e175eebf25ea",
   "metadata": {},
   "source": [
    "# Intel® VTune™ Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c938a-3a5d-417a-ac6e-e73071f7b0df",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "**Intel® VTune™ Profiler** optimizes application performance, system performance, and system configuration for HPC, cloud, IoT, media, storage, and more.\n",
    "- **CPU, GPU, and FPGA**: Tune the entire application’s performance―not just the accelerated portion.\n",
    "- **Multilingual**: Profile SYCL*, C, C++, C#, Fortran, OpenCL™ code, Python*, Google Go* programming language, Java*, .NET, Assembly, or any combination of languages.\n",
    "- **System or Application**: Get coarse-grained system data for an extended period or detailed results mapped to source code.\n",
    "- **Power**: Optimize performance while avoiding power- and thermal-related throttling. <br>\n",
    "\n",
    "**For profiling python workloads** <br>\n",
    "VTune requires minimal code modification. It also provides a GUI that is easy to use. It provides call stack information, flame graph, and hardware utilization. It can profile GPU workloads. It can profile individual threads. It provides memory consumption information. Profiling results can be shared very easily through web browser interface. It also gives low-level C, C++ functions that can be potential hotspots. The profiling overhead is high as compared to other profilers. <br>\n",
    "\n",
    "**To get started with Intel VTune** visit the article **[Get Started with Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/docs/vtune-profiler/get-started-guide/2023/overview.html)** and follow the instructions. <br>\n",
    "\n",
    "**To download the Intel VTune:**\n",
    "- **[As Part of the Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html)**: Intel VTune Profiler is included in the Intel® oneAPI Base Toolkit, which is a core set of tools and libraries for developing high-performance, data-centric applications across diverse architectures. \n",
    "- **[Stand-Alone Version (recommended for this notebook)](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler-download.html)**: A stand-alone download of Intel VTune Profiler is available. You can download binaries from Intel or choose your preferred repository.<br>\n",
    "\n",
    "**To get help about usage of Intel VTune** visit the article **[Intel® VTune™ Profiler User Guide](https://www.intel.com/content/www/us/en/docs/vtune-profiler/user-guide/2023-0/overview.html)**\n",
    "\n",
    "**To know more about Intel VTune** visit the article **[Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ded70e-fe61-44e6-aabb-63ea3d0208bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To Install VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207fb57-9202-4324-bad5-d59afd57c328",
   "metadata": {},
   "source": [
    "1. **[Install Intel® VTune™ Profiler on your Linux* system.](https://www.intel.com/content/www/us/en/develop/documentation/vtune-install-guide/top/linux.html)**\n",
    "\n",
    "2. Build your application with symbol information and in Release mode with all optimizations enabled. For detailed information on compiler settings, see the **[VTune Profiler online user guide.](https://software.intel.com/en-us/vtune-amplifier-help-compiler-switches-for-performance-analysis-on-windows-targets)** <br>\n",
    "You can also use the matrix sample application available in <install_directory>\\sample\\matrix. You can see sample results in `<install-dir>\\sample (matrix)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad7390-f04a-4c4c-b9a4-6573abf9e033",
   "metadata": {},
   "source": [
    "3. Set up the environment variables: <br>\n",
    "    `source <install-dir>/setvars.sh`\n",
    "\n",
    "    By default, the `install-dir` is: <br>\n",
    "    \n",
    "    `$HOME/intel/oneapi/` when installed with user permissions, and  <br>\n",
    "\n",
    "    `/opt/intel/oneapi/` when installed with root permissions. <br>\n",
    "     If you want to know how to get started with VTune and learn while using the VTune GUI visit this **[article](https://www.intel.com/content/www/us/en/docs/vtune-profiler/get-started-guide/2023/linux-os.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5453e1b-cf13-461f-b3ba-b39b08039202",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc07592-4530-4d93-937c-2e06efe1b84c",
   "metadata": {},
   "source": [
    "When using VTune for profiling Python code, **DL_VTune** is a handy tool as it provides **ITT_TAGGING**, which can be used to profile blocks of code. We can choose **different starting and end points** and give names to different sections for profiling. <br>\n",
    "To know more about **DL_VTune** visit its **[GitHub repo](https://github.com/intel-sandbox/DL_VTune)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2f4a1-82b8-4ab1-8177-b6150b3f1157",
   "metadata": {},
   "source": [
    "#### Pre-requisites for DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce40f60-922a-4e77-9eb2-7f66a87146ab",
   "metadata": {},
   "source": [
    "- Intel VTune Profiler installation **[Refer to instructions here](#Install-and-Initialize-VTune)**\n",
    "- TensorFlow or PyTorch installation. Need TensorFlow or PyTorch version with oneDNN ITT Tagging support. Please refer **[dev_guide_profilers](https://oneapi-src.github.io/oneDNN/dev_guide_profilers.html)** for details. <br>\n",
    "**Note this is only needed if your workload has Tensorflow or PyTorch code.** In our example we donot have tensorflow or Pytorch code, so we do not need it.\n",
    "- `itt-python` installation: <br>\n",
    "`conda install -c conda-forge itt-python`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d99141-8de4-4af3-a5f9-ca4955d6f004",
   "metadata": {},
   "source": [
    "##### Install DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280fde1-ab7f-44fb-9d50-46184fc99f9b",
   "metadata": {},
   "source": [
    "After all the Pre-requisites are installed, follow the below steps\n",
    "- Clone the **[DL_VTune github repo](https://github.com/intel-sandbox/DL_VTune)** <br>\n",
    "    `git clone https://github.com/intel-sandbox/DL_VTune` <br>\n",
    "    `cd DL_VTune` <br>\n",
    "    `pip install .` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d5203-7fac-4fff-80c0-df460f622df7",
   "metadata": {},
   "source": [
    "##### Using DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8294f06-5e42-4c02-91c2-8a67b7969fdb",
   "metadata": {},
   "source": [
    "We can create different domains so that VTune results can be visualized easily. \n",
    "**NOTE:** below is an example template to use **itt_tagging**. Change the  **\"domain\"** and **\"DLTasks\"** according to your need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2dd62e7-2158-439c-b080-9c137d300392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itt\n",
    "# # ... \n",
    "# domain = itt.domain_create(\"domain\")  ##Create Domain \n",
    "# itt.task_begin(domain, \"DLTasks\")     ##Begin a task\n",
    "# # ... do the tasks                    #Code that is to be monitored\n",
    "# itt.task_end(domain)                  #End the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a91b4-df3b-449a-8d96-a12a6e8c4008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example to use **VTune** for **intelligent_indexing** ref kit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216bfc1-89ea-48ae-a8ce-739b08c35635",
   "metadata": {},
   "source": [
    "The **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** ref kit demonstrates one way of building an NLP pipeline for classifying documents to their respective topics and describe how we can leverage the **Intel® AI Analytics Toolkit (AI Kit)** to accelerate the pipeline.\n",
    "\n",
    "**Intel® AI Analytics Toolkit (AI Kit)** is used to achieve quick results even when the data for a model are huge. It provides the capability to reuse the code present in different languages so that the hardware utilization is optimized to provide these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11de80-c6bf-4eac-a12d-efec1699187c",
   "metadata": {},
   "source": [
    "The **Intelligent Indexing** ref kit has different Intel® oneAPI optimizations enabled like:\n",
    "- **[Intel® Distribution of Modin*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-of-modin.html#gs.v03x2l)**\n",
    "The Intel® Distribution of Modin* is a performant, parallel, and distributed dataframe system that is designed around enabling data scientists to be more productive. It provides drop-in acceleration to your existing **pandas** workflows. No upfront cost to learning a new API. Integrates with the Python* ecosystem. Seamlessly scales across multicores with Ray* and Dask* clusters (run on and with what you have)\n",
    "- **[Intel® Extension for Scikit-learn*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/scikit-learn.html)**\n",
    "Designed for data scientists, Intel® Extension for Scikit-Learn* is a seamless way to speed up your Scikit-learn applications for machine learning to solve real-world problems. This extension package dynamically patches scikit-learn estimators to use Intel® oneAPI Data Analytics Library (oneDAL) as the underlying solver, while achieving the speed up for your machine learning algorithms out-of-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3bb2a-cf92-463c-9876-e6e3b6e53529",
   "metadata": {},
   "source": [
    "**NOTE** Please visit the **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** Ref kit page to know more about the kit.\n",
    "- Please follow the steps in github repo to clone and create the environment.\n",
    "- After creating environment install **DL_VTune** in both the environments **doc_class_stock** and **doc_class_intel** using instructions above.\n",
    "\n",
    "**We will be using **VTune** to profile this workload below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ca2e5-cf11-4acc-97ca-ae0baae983ff",
   "metadata": {},
   "source": [
    "To know more about different types of analysis options available with **VTune** visit the **[article.](https://www.intel.com/content/www/us/en/docs/vtune-profiler/user-guide/2023-1/running-command-line-analysis.html)** <br>\n",
    "To know how to use the command line interface for **VTune** visit the **[cheatsheet.](https://www.intel.com/content/dam/develop/external/us/en/documents/vtune-profiler-cheat-sheet.pdf)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455a23b-4eb6-41a2-b8f9-a6a92f5c88a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Profile the Intelligent Indexing Ref Kit with Stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8f5b13-1a39-4e46-b136-2cf5de295052",
   "metadata": {},
   "source": [
    "To run **performance profiling** on intelligent-indexing ref kit. \n",
    "\n",
    "- Navigate to `intelligent-indexing/src/`: `cd intelligent-indexing/src/`\n",
    "- Create a file **run_benchmarks_vtune.py**. We have given one for your reference. You can directly create a copy of it in the above directory. \n",
    "- Copy and paste the file at location **intelligent-indexing/src/**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8470e-c993-4c14-8f82-e5b9334ab5b3",
   "metadata": {},
   "source": [
    "Run the command below in the **Terminal** to **collect a performance snapshot** using stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1426e27-2120-47bb-a6dd-2f705429108d",
   "metadata": {},
   "source": [
    "`vtune -collect performance-snapshot -result-dir='../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/stock_results/performance_snapshot_results/' -- python  run_benchmarks_vtune.py -l ../logs/stock_stock.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040cf2a1-b6b6-4346-ba04-2655325c4b79",
   "metadata": {},
   "source": [
    "Run the command below in the **Terminal** to **collect hotspots** using stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466b195-8cc1-4668-b6ab-5f14bba6e540",
   "metadata": {},
   "source": [
    "`vtune -collect hotspots -result-dir='../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/stock_results/hotspots_results/' -- python  run_benchmarks_vtune.py -l ../logs/stock_stock.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881d64e-8aa2-4db9-a11c-154ea038d0ea",
   "metadata": {},
   "source": [
    "##### To visulaize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c41fc8-f036-47ab-ac91-599739ff8412",
   "metadata": {},
   "source": [
    "Make sure that you are in the same directory as before, `intelligent-indexing/src/`. <br>\n",
    "Run the below command in Terminal to visualize **VTune results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7864232-e87c-4ab5-8039-19feb5fc6987",
   "metadata": {},
   "source": [
    "`vtune-backend --web-port=8080 --data-directory=\"'../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/stock_results/\" --allow-remote-access`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef3291-beca-4fcf-8cc6-62b71d2d3513",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Intel oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314170e9-d79e-4577-964a-1e3f06153f01",
   "metadata": {},
   "source": [
    "To run **performance profiling** on intelligent-indexing ref kit. \n",
    "\n",
    "- Navigate to `intelligent-indexing/src/` : `cd intelligent-indexing/src/`\n",
    "- Create a file **run_benchmarks_vtune.py**. We have given one for your reference. You can directly create a copy of it in the above directory. \n",
    "- Copy and paste the file at location **intelligent-indexing/src/**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c427ac90-c3f1-4a3a-8d18-870cc787a137",
   "metadata": {},
   "source": [
    "Run the command below in the **Terminal** to **collect a performance snapshot** using oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d0b76-e00a-4111-9714-cda0887d21cf",
   "metadata": {},
   "source": [
    "`vtune -collect performance-snapshot -result-dir='../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/oneapi_optimized_results/performance_snapshot_results/' -- python  run_benchmarks_vtune.py -i -l ../logs/intel_intel.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aff11d-fcc5-401a-9398-19899890fe46",
   "metadata": {},
   "source": [
    "Run the command below in the **Terminal** to **collect hotspots** using oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d73d1-d794-4ddc-a123-4fd6b762c230",
   "metadata": {},
   "source": [
    "`vtune -collect hotspots -result-dir='../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/oneapi_optimized_results/hotspots_results/' -- python run_benchmarks_vtune.py -i -l ../logs/intel_intel.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75159b-aeb5-4f21-a0ea-2e3ee4678999",
   "metadata": {},
   "source": [
    "##### To visulaize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762af75-d48d-4ee8-b0a2-d176b4b40472",
   "metadata": {},
   "source": [
    "Make sure that you are in the same directory as before, `intelligent-indexing/src/`. <br>\n",
    "Run the below command in Terminal to visualize **VTune results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd79e7e-4db6-4796-8ed8-04188d527dd8",
   "metadata": {},
   "source": [
    "`vtune-backend --web-port=8080 --data-directory=\"../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/oneapi_optimized_results/\" --allow-remote-access`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386e25f-47c8-4135-8288-236ef74ece20",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02007b13-aa07-438e-bee9-63b074db57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should something be here? or describe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
