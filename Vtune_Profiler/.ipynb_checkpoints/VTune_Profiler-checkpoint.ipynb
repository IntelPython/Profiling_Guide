{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1688bc9-27e3-4728-abc9-e175eebf25ea",
   "metadata": {},
   "source": [
    "# Intel® VTune™ Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c938a-3a5d-417a-ac6e-e73071f7b0df",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Intel® VTune™ Profiler** optimizes application performance, system performance, and system configuration for HPC, cloud, IoT, media, storage, and more.\n",
    "\n",
    "- **CPU, GPU, and FPGA**: Tune the entire application’s performance―not just the accelerated portion.\n",
    "- **Multilingual**: Profile SYCL*, C, C++, C#, Fortran, OpenCL™ code, Python*, Google Go* programming language, Java*, .NET, Assembly, or any combination of languages.\n",
    "- **System or Application**: Get coarse-grained system data for an extended period or detailed results mapped to source code.\n",
    "- **Power**: Optimize performance while avoiding power- and thermal-related throttling. <br>\n",
    "\n",
    "To get started with Intel VTune visit the article **[Get Started with Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/docs/vtune-profiler/get-started-guide/2023/overview.html)** <br>\n",
    "\n",
    "To download the Intel VTune\n",
    "- **[As Part of the Toolkit](https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html)**: Intel VTune Profiler is included in the Intel® oneAPI Base Toolkit, which is a core set of tools and libraries for developing high-performance, data-centric applications across diverse architectures. \n",
    "- **[Stand-Alone Version](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler-download.html)**: A stand-alone download of Intel VTune Profiler is available. You can download binaries from Intel or choose your preferred repository. <br>\n",
    "\n",
    "To get help about usage of Intel VTune visit the article **[Intel® VTune™ Profiler User Guide](https://www.intel.com/content/www/us/en/docs/vtune-profiler/user-guide/2023-0/overview.html)**\n",
    "\n",
    "To know more about Intel VTune visit the article **[Intel® VTune™ Profiler](https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ded70e-fe61-44e6-aabb-63ea3d0208bc",
   "metadata": {},
   "source": [
    "## Steps to install and initialize VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207fb57-9202-4324-bad5-d59afd57c328",
   "metadata": {},
   "source": [
    " - **[Install Intel® VTune™ Profiler on your Linux* system.](https://www.intel.com/content/www/us/en/develop/documentation/vtune-install-guide/top/linux.html)**\n",
    "\n",
    "- Build your application with symbol information and in Release mode with all optimizations enabled. For detailed information on compiler settings, see the **[VTune Profiler online user guide.](https://software.intel.com/en-us/vtune-amplifier-help-compiler-switches-for-performance-analysis-on-windows-targets)** <br>\n",
    "You can also use the matrix sample application available in <install_directory>\\sample\\matrix. You can see sample results in <install-dir>\\sample (matrix).\n",
    "\n",
    "- Set up the environment variables: <br>\n",
    "source <install-dir>/setvars.sh <br>\n",
    "By default, the <install-dir> is: <br>\n",
    "$HOME/intel/oneapi/ when installed with user permissions; <br>\n",
    "/opt/intel/oneapi/ when installed with root permissions. <br>\n",
    "    \n",
    "If you want to know how to get started with Vtune and learn using VTune GUI visit the **[article](https://www.intel.com/content/www/us/en/docs/vtune-profiler/get-started-guide/2023/linux-os.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5453e1b-cf13-461f-b3ba-b39b08039202",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc07592-4530-4d93-937c-2e06efe1b84c",
   "metadata": {},
   "source": [
    "To use VTune for profiling python code. DL_VTune is a handy tool as it provides **ITT_TAGGING**, which can be used to profile blocks of code. We can choose **different starting and end points** and give names to different sections for profiling. <br>\n",
    "To know more about **DL_VTune** visit the **[github repo](https://github.com/intel-sandbox/DL_VTune)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2f4a1-82b8-4ab1-8177-b6150b3f1157",
   "metadata": {},
   "source": [
    "### Pre-requisites for DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce40f60-922a-4e77-9eb2-7f66a87146ab",
   "metadata": {},
   "source": [
    "- Intel VTune Profiler installation (Use instructions above)\n",
    "- TensorFlow or PyTorch installation (If you want to profile **[Intelligent-Indexing](https://github.com/oneapi-src/intelligent-indexing)** toolkit see instructions below to set up **doc_class_stock** and **doc_class_intel** environments.) <br> Need TensorFlow or PyTorch version with oneDNN ITT Tagging support.\n",
    "Please refer **[dev_guide_profilers](https://oneapi-src.github.io/oneDNN/dev_guide_profilers.html)** for details.\n",
    "- itt-python installation :\n",
    "```\n",
    "conda install -c conda-forge itt-python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d99141-8de4-4af3-a5f9-ca4955d6f004",
   "metadata": {},
   "source": [
    "### Install DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280fde1-ab7f-44fb-9d50-46184fc99f9b",
   "metadata": {},
   "source": [
    "After all the Pre-requisites are installed, follow the below steps\n",
    "- Clone the **[DL_VTune github repo](https://github.com/intel-sandbox/DL_VTune)**\n",
    "```\n",
    "git clone https://github.com/intel-sandbox/DL_VTune\n",
    "cd DL_VTune\n",
    "pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d5203-7fac-4fff-80c0-df460f622df7",
   "metadata": {},
   "source": [
    "### Using DL_VTune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8294f06-5e42-4c02-91c2-8a67b7969fdb",
   "metadata": {},
   "source": [
    "We will create different domains so that VTune results can be visualized easily. \n",
    "```\n",
    "import itt\n",
    "# ... \n",
    "domain = itt.domain_create(\"domain\")\n",
    "itt.task_begin(domain, \"DLTasks\")\n",
    "# ... do the DLTasks...\n",
    "itt.task_end(domain)\n",
    "```\n",
    "**NOTE:** please change **\"domain\"** and **\"DLTasks\"** according to your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a91b4-df3b-449a-8d96-a12a6e8c4008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example to use **VTune** for **intelligent_indexing** ref kit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216bfc1-89ea-48ae-a8ce-739b08c35635",
   "metadata": {},
   "source": [
    "The **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** ref kit demonstrates one way of building an NLP pipeline for classifying documents to their respective topics and describe how we can leverage the **Intel® AI Analytics Toolkit (AI Kit)** to accelerate the pipeline.\n",
    "\n",
    "**Intel® AI Analytics Toolkit (AI Kit)** is used to achieve quick results even when the data for a model are huge. It provides the capability to reuse the code present in different languages so that the hardware utilization is optimized to provide these results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11de80-c6bf-4eac-a12d-efec1699187c",
   "metadata": {},
   "source": [
    "The **Intelligent Indexing** ref kit has different Intel® oneAPI optimizations enabled like:\n",
    "- **[Intel® Distribution of Modin*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/distribution-of-modin.html#gs.v03x2l)**\n",
    "The Intel® Distribution of Modin* is a performant, parallel, and distributed dataframe system that is designed around enabling data scientists to be more productive. It provides drop-in acceleration to your existing **pandas** workflows. No upfront cost to learning a new API. Integrates with the Python* ecosystem. Seamlessly scales across multicores with Ray* and Dask* clusters (run on and with what you have)\n",
    "- **[Intel® Extension for Scikit-learn*](https://www.intel.com/content/www/us/en/developer/tools/oneapi/scikit-learn.html)**\n",
    "Designed for data scientists, Intel® Extension for Scikit-Learn* is a seamless way to speed up your Scikit-learn applications for machine learning to solve real-world problems. This extension package dynamically patches scikit-learn estimators to use Intel® oneAPI Data Analytics Library (oneDAL) as the underlying solver, while achieving the speed up for your machine learning algorithms out-of-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3bb2a-cf92-463c-9876-e6e3b6e53529",
   "metadata": {},
   "source": [
    "**NOTE** Please visit the **[Intelligent Indexing](https://github.com/oneapi-src/intelligent-indexing)** Ref kit page to know more about the kit.\n",
    "- Please follow the steps in github repo to clone and create the environment.\n",
    "- After creating environment install **DL_VTune** in both the environments **doc_class_stock** and **doc_class_intel** using instructions above.\n",
    "\n",
    "We will be using **VTune** to profile this workload below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ca2e5-cf11-4acc-97ca-ae0baae983ff",
   "metadata": {},
   "source": [
    "To know more about different types of analysis options available with **VTune** visit the **[article.](https://www.intel.com/content/www/us/en/docs/vtune-profiler/user-guide/2023-1/running-command-line-analysis.html)** <br>\n",
    "To know how to use the command line interface for **VTune** visit the **[cheatsheet.](https://www.intel.com/content/dam/develop/external/us/en/documents/vtune-profiler-cheat-sheet.pdf)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455a23b-4eb6-41a2-b8f9-a6a92f5c88a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Stock packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8f5b13-1a39-4e46-b136-2cf5de295052",
   "metadata": {},
   "source": [
    "To run **performance profiling** on ref kit. **Navigate to 'intelligent-indexing/src/'** \n",
    "```\n",
    "cd intelligent-indexing/src/\n",
    "```\n",
    "- Create a file **run_benchmarks_vtune.py** as shown above. We have given one for your reference. \n",
    "- Copy and paste the file at location **intelligent-indexing/src/**\n",
    "- Run the command below in the **terminal** to **collect performance snapshot** using oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654a65a-f06f-4a6a-8c23-21bc50974ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vtune -collect performance-snapshot -result-dir='../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/stock_results/performance_snapshot_results/' -- python  run_benchmarks_vtune.py -l ../logs/stock_stock.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881d64e-8aa2-4db9-a11c-154ea038d0ea",
   "metadata": {},
   "source": [
    "##### To visulaize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c41fc8-f036-47ab-ac91-599739ff8412",
   "metadata": {},
   "source": [
    "In the same directory as above **intelligent-indexing/src/**. <br>\n",
    "Run the below command in the terminal to visualize **VTune results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db953dcf-2400-448e-ac68-713dcee9b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !vtune-backend --web-port=8080 --data-directory=\"'../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/stock_results/performance_snapshot_results/\" --allow-remote-access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef3291-beca-4fcf-8cc6-62b71d2d3513",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Profile Intelligent Indexing Ref Kit with Intel oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314170e9-d79e-4577-964a-1e3f06153f01",
   "metadata": {},
   "source": [
    "To run **performance profiling** on ref kit. **Navigate to 'intelligent-indexing/src/'** \n",
    "```\n",
    "cd intelligent-indexing/src/\n",
    "```\n",
    "- Create a file **run_benchmarks_vtune.py** as shown above. We have given one for your reference. \n",
    "- Copy and paste the file at location **intelligent-indexing/src/**\n",
    "- Run the command below in the **terminal** to **collect performance snapshot** using oneAPI optimized packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4badfe-e470-4729-86d8-f6daed342344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vtune -collect performance-snapshot -result-dir='../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/oneapi_optimized_results/performance_snapshot_results/' -- python  run_benchmarks_vtune.py -i -l ../logs/intel_intel.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75159b-aeb5-4f21-a0ea-2e3ee4678999",
   "metadata": {},
   "source": [
    "##### To visulaize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762af75-d48d-4ee8-b0a2-d176b4b40472",
   "metadata": {},
   "source": [
    "In the same directory as above **intelligent-indexing/src/**. <br>\n",
    "Run the below command in the terminal to visualize **VTune results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb0eccd-176d-4881-89ec-03faf62b0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vtune-backend --web-port=8080 --data-directory=\"../Profiling_Guide/Vtune_Profiler/VTune_Profiler_Results/oneapi_optimized_results/performance_snapshot_results/\" --allow-remote-access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386e25f-47c8-4135-8288-236ef74ece20",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
